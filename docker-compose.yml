# docker-compose.yml (Simplified for Job Chain)

services:
  # FastAPI Backend (CPU-only, no models loaded)
  api:
    build:
      context: .
      dockerfile: Dockerfile.api
    ports:
      - "8000:8000"
    environment:
      - WORKER_TYPE=api
      - QDRANT_HOST=qdrant
      - QDRANT_PORT=6333
      - DEVICE=cpu
      - LOAD_EMBEDDING_MODEL=false
      - LOAD_LLM_MODEL=false
      - LOAD_COLBERT_MODEL=false
      - LOAD_WHISPER_MODEL=false
      - LOG_LEVEL=INFO
      - CONTAINER_RUNTIME=docker
      - REDIS_HOST=redis
      - REDIS_PORT=6379
    volumes:
      - ./src:/app/src
      - ./data:/app/data
      - ./models:/app/models
      - ./logs:/app/logs
    env_file:
      - .env
    depends_on:
      - qdrant
      - redis
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # GPU Worker - handles all GPU tasks (inference, embedding, transcription)
  worker-gpu:
    build:
      context: .
      dockerfile: Dockerfile.api
    runtime: nvidia
    command: python -m dramatiq src.core.background --processes 1 --threads 1 --queues inference_tasks,embedding_tasks,transcription_tasks
    environment:
      - WORKER_TYPE=gpu
      - DEVICE=cuda
      - USE_FP16=true
      - LOAD_EMBEDDING_MODEL=true
      - LOAD_LLM_MODEL=true
      - LOAD_COLBERT_MODEL=true
      - LOAD_WHISPER_MODEL=true
      - CONTAINER_RUNTIME=docker
      - NVIDIA_VISIBLE_DEVICES=all
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - LOG_LEVEL=INFO
      - PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True
    volumes:
      - ./src:/app/src
      - ./data:/app/data
      - ./models:/app/models
      - ./logs:/app/logs
    depends_on:
      - redis
      - qdrant
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "bash", "-c", "ps aux | grep dramatiq | grep -v grep"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  # CPU Worker - handles document processing, PDF parsing, OCR
  worker-cpu:
    build:
      context: .
      dockerfile: Dockerfile.api
    command: python -m dramatiq src.core.background --processes 2 --threads 4 --queues cpu_tasks
    environment:
      - WORKER_TYPE=cpu
      - DEVICE=cpu
      - CUDA_VISIBLE_DEVICES=""  # Hide GPU
      - LOAD_EMBEDDING_MODEL=false
      - LOAD_LLM_MODEL=false
      - LOAD_COLBERT_MODEL=false
      - LOAD_WHISPER_MODEL=false
      - USE_PDF_OCR=true
      - CONTAINER_RUNTIME=docker
      - REDIS_HOST=redis

  # Streamlit UI
  ui:
    build:
      context: .
      dockerfile: Dockerfile.streamlit
    ports:
      - "8501:8501"
    environment:
      - API_URL=http://api:8000
      - CONTAINER_RUNTIME=docker
      - REDIS_HOST=redis
      - REDIS_PORT=6379
    volumes:
      - ./src:/app/src
      - ./data:/app/data
      - ./models:/app/models
      - ./logs:/app/logs
    env_file:
      - .env
    depends_on:
      - api
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8501"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Qdrant Vector Database
  qdrant:
    image: qdrant/qdrant:latest
    ports:
      - "6333:6333"
      - "6334:6334"
    volumes:
      - qdrant-data:/qdrant/storage
    environment:
      - QDRANT_ALLOW_CORS=true
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:6333/collections"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 40s

  # Redis for Background Task Queue
  redis:
    image: redis:7.0-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    command: redis-server --appendonly yes --maxmemory 512mb --maxmemory-policy allkeys-lru
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3

volumes:
  qdrant-data:
  redis-data: