services:
  # FastAPI Backend
  api:
    build:
      context: .
      dockerfile: Dockerfile.api
    ports:
      - "8000:8000"
    runtime: nvidia
    environment:
      - WORKER_TYPE=api
      - QDRANT_HOST=qdrant
      - QDRANT_PORT=6333
      - DEVICE=cuda
      - USE_FP16=true
      - PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True
      - WHISPER_MODEL_SIZE=small
      - USE_YOUTUBE_CAPTIONS=false
      - USE_WHISPER_AS_FALLBACK=false
      - FORCE_WHISPER=true
      - USE_PDF_OCR=true
      - LOG_LEVEL=INFO
      - CONTAINER_RUNTIME=docker
      - NVIDIA_VISIBLE_DEVICES=all
      - REDIS_HOST=redis
      - REDIS_PORT=6379
    volumes:
      - ./data:/app/data
      - ./models:/app/models
      - ./logs:/app/logs
    env_file:
      - .env
    depends_on:
      - qdrant
      - redis
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # GPU Worker - prioritizes inference over other GPU tasks
  worker-gpu:
    build:
      context: .
      dockerfile: Dockerfile.api
    runtime: nvidia
    command: python -m dramatiq src.core.background_tasks --processes 1 --threads 1 --queues inference_tasks,gpu_tasks
    environment:
      - WORKER_TYPE=gpu
      - QDRANT_HOST=qdrant
      - QDRANT_PORT=6333
      - DEVICE=cuda
      - USE_FP16=true
      - PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True
      - WHISPER_MODEL_SIZE=small
      - USE_YOUTUBE_CAPTIONS=false
      - USE_WHISPER_AS_FALLBACK=false
      - FORCE_WHISPER=true
      - USE_PDF_OCR=true
      - CONTAINER_RUNTIME=docker
      - NVIDIA_VISIBLE_DEVICES=all
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - LOG_LEVEL=INFO
    volumes:
      - ./data:/app/data
      - ./models:/app/models
      - ./logs:/app/logs
    env_file:
      - .env
    ulimits:
      memlock: -1
      stack: 67108864
    shm_size: 8gb
    depends_on:
      - qdrant
      - redis
    deploy:
      replicas: 1  # Just one GPU worker
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "bash", "-c", "ps aux | grep dramatiq | grep -v grep"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  # CPU Worker - handles PDF processing and text operations
  worker-cpu:
    build:
      context: .
      dockerfile: Dockerfile.api
    command: python -m dramatiq src.core.background_tasks --processes 4 --threads 1 --queues cpu_tasks
    environment:
      - WORKER_TYPE=cpu
      - QDRANT_HOST=qdrant
      - QDRANT_PORT=6333
      - DEVICE=cpu
      - CUDA_VISIBLE_DEVICES=""  # Hide GPU
      - WHISPER_MODEL_SIZE=small
      - USE_YOUTUBE_CAPTIONS=false
      - USE_WHISPER_AS_FALLBACK=false
      - FORCE_WHISPER=true
      - USE_PDF_OCR=true
      - CONTAINER_RUNTIME=docker
      - NVIDIA_VISIBLE_DEVICES=all
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - LOG_LEVEL=INFO
    volumes:
      - ./data:/app/data
      - ./models:/app/models
      - ./logs:/app/logs
    env_file:
      - .env
    depends_on:
      - qdrant
      - redis
    deploy:
      replicas: 1  # Scale this for more parallel CPU processing
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "bash", "-c", "ps aux | grep dramatiq | grep -v grep"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  # Job Cleanup Service - periodically purges old completed jobs
  job-cleanup:
    build:
      context: .
      dockerfile: Dockerfile.api
    command: python /app/job_cleanup_service.py --retention-days 7 --interval 3600
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - JOB_RETENTION_DAYS=7
      - CLEANUP_INTERVAL=3600
      - LOG_LEVEL=INFO
    volumes:
      - ./logs:/app/logs
    depends_on:
      - redis
    restart: unless-stopped

  # Streamlit UI
  ui:
    build:
      context: .
      dockerfile: Dockerfile.streamlit
    ports:
      - "8501:8501"
    environment:
      - API_URL=http://api:8000
      - CONTAINER_RUNTIME=docker
      - REDIS_HOST=redis
      - REDIS_PORT=6379
    volumes:
      - ./data:/app/data
      - ./models:/app/models
      - ./logs:/app/logs
    env_file:
      - .env
    depends_on:
      - api
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8501"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Qdrant Vector Database
  qdrant:
    image: qdrant/qdrant:latest
    ports:
      - "6333:6333"
      - "6334:6334"
    volumes:
      - qdrant-data:/qdrant/storage
    environment:
      - QDRANT_ALLOW_CORS=true
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:6333/readiness"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 40s

  # Redis for Background Task Queue
  redis:
    image: redis:7.0-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    command: redis-server --appendonly yes --maxmemory 512mb --maxmemory-policy allkeys-lru
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3

volumes:
  qdrant-data:
  redis-data: