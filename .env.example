# Specific model names - change these to use different models
DEFAULT_EMBEDDING_MODEL=bge-small-en-v1.5
DEFAULT_COLBERT_MODEL=colbertv2.0
DEFAULT_LLM_MODEL=DeepSeek-R1-Distill-Qwen-7B
DEFAULT_WHISPER_MODEL=medium

# API settings
API_KEY=default-api-key
API_AUTH_ENABLED=true

# Server settings
HOST=0.0.0.0
PORT=8000

# Qdrant settings
QDRANT_HOST=qdrant
QDRANT_PORT=6333
QDRANT_COLLECTION=automotive_specs

# GPU settings
DEVICE=cuda:0
USE_FP16=true
BATCH_SIZE=16

# Model settings
#
# HOST_MODELS_DIR: Base directory on the host machine for downloading models
# CONTAINER_MODELS_DIR: Base directory inside the container for loading models
HOST_MODELS_DIR=models
CONTAINER_MODELS_DIR=/app/models

# Paths for specific model types (within the base directories)
# These paths will be combined with either HOST_MODELS_DIR or CONTAINER_MODELS_DIR
EMBEDDING_MODEL_PATH=embeddings
COLBERT_MODEL_PATH=colbert
LLM_MODEL_PATH=llm
WHISPER_MODEL_PATH=whisper

# Hugging Face model identifiers (used for downloading)
HF_EMBEDDING_MODEL=BAAI/bge-small-en-v1.5
HF_COLBERT_MODEL=colbert-ir/colbertv2.0
HF_DEEPSEEK_MODEL=deepseek-ai/DeepSeek-R1-Distill-Qwen-7B
HF_WHISPER_MODEL=openai/whisper-medium

# LLM settings
LLM_USE_4BIT=true
LLM_USE_8BIT=false
LLM_TEMPERATURE=0.1
LLM_MAX_TOKENS=512

# Whisper settings
WHISPER_MODEL_SIZE=medium
USE_YOUTUBE_CAPTIONS=false
USE_WHISPER_AS_FALLBACK=false
FORCE_WHISPER=true

# PDF OCR settings
USE_PDF_OCR=true
OCR_LANGUAGES=eng

# Retrieval settings
RETRIEVER_TOP_K=20
RERANKER_TOP_K=5
COLBERT_BATCH_SIZE=16

# Chunking settings
CHUNK_SIZE=1000
CHUNK_OVERLAP=200

# Data directory paths
# When running in Docker, these are mounted from host paths
# to container paths as specified in docker-compose.yml
HOST_DATA_DIR=data
CONTAINER_DATA_DIR=/app/data
UPLOAD_DIR=uploads

# Cache directory settings
TRANSFORMERS_CACHE=/app/models/cache
HF_HOME=/app/models/hub