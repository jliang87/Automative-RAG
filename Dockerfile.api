# Use NVIDIA CUDA image as the base image for GPU support
FROM nvidia/cuda:12.1.1-cudnn8-runtime-ubuntu22.04

# Set environment variables
ENV PYTHONDONTWRITEBYTECODE=1 \
    PYTHONUNBUFFERED=1 \
    POETRY_VERSION=1.7.1 \
    POETRY_HOME="/opt/poetry" \
    POETRY_VIRTUALENVS_IN_PROJECT=false \
    POETRY_NO_INTERACTION=1 \
    DEBIAN_FRONTEND=noninteractive \
    TRANSFORMERS_CACHE="/app/models/cache" \
    HF_HOME="/app/models/hub"

# Install system dependencies
RUN apt-get update && apt-get install -y --no-install-recommends \
    python3.10 \
    python3.10-dev \
    python3-pip \
    python3-venv \
    ffmpeg \
    curl \
    gcc \
    g++ \
    git \
    libgl1-mesa-glx \
    libglib2.0-0 \
    poppler-utils \
    tesseract-ocr \
    ghostscript \
    libtesseract-dev \
    libleptonica-dev \
    pkg-config \
    && rm -rf /var/lib/apt/lists/*

# Alias python to python3.10
RUN ln -sf /usr/bin/python3.10 /usr/bin/python3 && ln -sf /usr/bin/python3 /usr/bin/python

# Install Poetry
RUN curl -sSL https://install.python-poetry.org | python3 -
ENV PATH="${POETRY_HOME}/bin:$PATH"

# Set up working directory
WORKDIR /app

# Copy pyproject.toml and poetry.lock
COPY pyproject.toml poetry.lock* ./

# Install dependencies with GPU support
RUN poetry config virtualenvs.create false \
    && poetry install --no-interaction --no-ansi --no-root --no-dev

# Install additional dependencies for GPU-based models
RUN pip install --no-cache-dir bitsandbytes==0.43.0 accelerate==0.28.0 \
    && pip install --no-cache-dir paddlepaddle-gpu==2.5.2 --index-url https://mirror.baidu.com/pypi/simple

# Create necessary directories
RUN mkdir -p /app/data/youtube /app/data/bilibili /app/data/uploads /app/models/cache /app/models/hub

# Download and cache models
RUN python -c "import torch; print(f'PyTorch CUDA available: {torch.cuda.is_available()}')" \
    && python -c "from transformers import AutoTokenizer; AutoTokenizer.from_pretrained('colbert-ir/colbertv2.0', use_fast=True)" \
    && python -c "from sentence_transformers import SentenceTransformer; SentenceTransformer('BAAI/bge-small-en-v1.5')" \
    && python -c "import whisper; whisper.load_model('base')"

# Download DeepSeek model
RUN python -c "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig; \
    import torch; \
    model_name='deepseek-ai/deepseek-coder-6.7b-instruct'; \
    print(f'Downloading {model_name}...'); \
    tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True); \
    quantization_config = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_compute_dtype=torch.float16); \
    model = AutoModelForCausalLM.from_pretrained(model_name, quantization_config=quantization_config, device_map='auto', trust_remote_code=True); \
    print('Model downloaded successfully!')"

# Copy the rest of the application
COPY . .

# Set up Tesseract and PaddleOCR data directories
ENV TESSDATA_PREFIX=/usr/share/tesseract-ocr/4.00/tessdata
ENV FLAGS_allocator_strategy=naive_best_fit
ENV FLAGS_fraction_of_gpu_memory_to_use=0.8

# Health check
HEALTHCHECK --interval=30s --timeout=30s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

# Command to run the application
CMD ["uvicorn", "src.api.main:app", "--host", "0.0.0.0", "--port", "8000"]