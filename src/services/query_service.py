import uuid
import json
import logging
from typing import Dict, List, Any, Optional
from datetime import datetime

from src.models.schema import (
    EnhancedQueryRequest,
    EnhancedQueryResponse,
    EnhancedBackgroundJobResponse,
    QueryMode,
    QueryValidationResult,
    ValidationType,
    DocumentResponse
)
from src.services.validation_service import ValidationService
from src.services.orchestration_service import OrchestrationService
from src.services.document_processing_service import DocumentProcessingService
from src.services.response_processing_service import ResponseProcessingService
from src.core.orchestration.job_tracker import job_tracker
from src.core.orchestration.job_chain import job_chain

logger = logging.getLogger(__name__)


class QueryService:
    """
    Core business logic for query processing.
    Orchestrates the entire query workflow without HTTP concerns.
    """

    def __init__(self,
                 validation_service: ValidationService,
                 orchestration_service: OrchestrationService,
                 document_service: DocumentProcessingService,
                 response_service: ResponseProcessingService):
        self.validation_service = validation_service
        self.orchestration_service = orchestration_service
        self.document_service = document_service
        self.response_service = response_service

        # Query mode configurations (moved from router)
        self.query_mode_configs = self._initialize_query_mode_configs()

    def _initialize_query_mode_configs(self) -> Dict[QueryMode, Dict[str, Any]]:
        """Initialize query mode configurations."""
        return {
            QueryMode.FACTS: {
                "mode": QueryMode.FACTS,
                "icon": "ğŸ“Œ",
                "name": "è½¦è¾†è§„æ ¼æŸ¥è¯¢",
                "description": "éªŒè¯å…·ä½“çš„è½¦è¾†è§„æ ¼å‚æ•°",
                "use_case": "æŸ¥è¯¢ç¡®åˆ‡çš„æŠ€æœ¯è§„æ ¼ã€é…ç½®ä¿¡æ¯",
                "two_layer": False,
                "is_default": True,
                "examples": [
                    "2023å¹´å®é©¬X5çš„åå¤‡ç®±å®¹ç§¯æ˜¯å¤šå°‘ï¼Ÿ",
                    "ç‰¹æ–¯æ‹‰Model 3çš„å……ç”µé€Ÿåº¦å‚æ•°",
                    "å¥”é©°Eçº§ä½¿ç”¨ä»€ä¹ˆè½®èƒå‹å·ï¼Ÿ"
                ]
            },
            QueryMode.FEATURES: {
                "mode": QueryMode.FEATURES,
                "icon": "ğŸ’¡",
                "name": "æ–°åŠŸèƒ½å»ºè®®",
                "description": "è¯„ä¼°æ˜¯å¦åº”è¯¥æ·»åŠ æŸé¡¹åŠŸèƒ½",
                "use_case": "äº§å“å†³ç­–ï¼ŒåŠŸèƒ½è§„åˆ’",
                "two_layer": True,
                "examples": [
                    "æ˜¯å¦åº”è¯¥ä¸ºç”µåŠ¨è½¦å¢åŠ æ°›å›´ç¯åŠŸèƒ½ï¼Ÿ",
                    "å¢åŠ æ¨¡æ‹Ÿå¼•æ“å£°éŸ³å¯¹ç”¨æˆ·ä½“éªŒçš„å½±å“",
                    "ARæŠ¬å¤´æ˜¾ç¤ºå™¨å€¼å¾—æŠ•èµ„å—ï¼Ÿ"
                ]
            },
            QueryMode.TRADEOFFS: {
                "mode": QueryMode.TRADEOFFS,
                "icon": "ğŸ§¾",
                "name": "æƒè¡¡åˆ©å¼Šåˆ†æ",
                "description": "åˆ†æè®¾è®¡é€‰æ‹©çš„ä¼˜ç¼ºç‚¹",
                "use_case": "è®¾è®¡å†³ç­–ï¼ŒæŠ€æœ¯é€‰å‹",
                "two_layer": True,
                "examples": [
                    "ä½¿ç”¨æ¨¡æ‹Ÿå£°éŸ³ vs è‡ªç„¶é™éŸ³çš„åˆ©å¼Š",
                    "ç§»é™¤ç‰©ç†æŒ‰é”®çš„ä¼˜ç¼ºç‚¹åˆ†æ",
                    "å¤§å±å¹• vs ä¼ ç»Ÿä»ªè¡¨ç›˜çš„å¯¹æ¯”"
                ]
            },
            QueryMode.SCENARIOS: {
                "mode": QueryMode.SCENARIOS,
                "icon": "ğŸ§©",
                "name": "ç”¨æˆ·åœºæ™¯åˆ†æ",
                "description": "è¯„ä¼°åŠŸèƒ½åœ¨å®é™…ä½¿ç”¨åœºæ™¯ä¸­çš„è¡¨ç°",
                "use_case": "ç”¨æˆ·ä½“éªŒè®¾è®¡ï¼Œäº§å“è§„åˆ’",
                "two_layer": True,
                "examples": [
                    "é•¿é€”æ—…è¡Œæ—¶è¿™ä¸ªåŠŸèƒ½å¦‚ä½•è¡¨ç°ï¼Ÿ",
                    "å®¶åº­ç”¨æˆ·åœ¨æ—¥å¸¸é€šå‹¤ä¸­çš„ä½“éªŒå¦‚ä½•ï¼Ÿ",
                    "å¯’å†·æ°”å€™ä¸‹çš„æ€§èƒ½è¡¨ç°åˆ†æ"
                ]
            },
            QueryMode.DEBATE: {
                "mode": QueryMode.DEBATE,
                "icon": "ğŸ—£ï¸",
                "name": "å¤šè§’è‰²è®¨è®º",
                "description": "æ¨¡æ‹Ÿä¸åŒè§’è‰²çš„è§‚ç‚¹å’Œè®¨è®º",
                "use_case": "å†³ç­–æ”¯æŒï¼Œå…¨é¢è¯„ä¼°",
                "two_layer": False,
                "examples": [
                    "äº§å“ç»ç†ã€å·¥ç¨‹å¸ˆå’Œç”¨æˆ·ä»£è¡¨å¦‚ä½•çœ‹å¾…è‡ªåŠ¨é©¾é©¶åŠŸèƒ½ï¼Ÿ",
                    "ä¸åŒå›¢é˜Ÿå¯¹ç”µæ± æŠ€æœ¯è·¯çº¿çš„è§‚ç‚¹",
                    "å…³äºè½¦å†…ç©ºé—´è®¾è®¡çš„å¤šæ–¹è®¨è®º"
                ]
            },
            QueryMode.QUOTES: {
                "mode": QueryMode.QUOTES,
                "icon": "ğŸ”",
                "name": "åŸå§‹ç”¨æˆ·è¯„è®º",
                "description": "æå–ç›¸å…³çš„ç”¨æˆ·è¯„è®ºå’Œåé¦ˆ",
                "use_case": "å¸‚åœºç ”ç©¶ï¼Œç”¨æˆ·æ´å¯Ÿ",
                "two_layer": False,
                "examples": [
                    "ç”¨æˆ·å¯¹ç»­èˆªé‡Œç¨‹çš„çœŸå®è¯„ä»·",
                    "å…³äºå†…é¥°è´¨é‡çš„ç”¨æˆ·åé¦ˆ",
                    "å……ç”µä½“éªŒçš„ç”¨æˆ·è¯„è®ºæ‘˜å½•"
                ]
            }
        }

    async def process_query(self, request: EnhancedQueryRequest) -> EnhancedBackgroundJobResponse:
        """
        Core business logic for processing queries.
        Moved from handle_unified_query_with_validation().
        """
        try:
            job_id = str(uuid.uuid4())

            # Validate query mode
            if request.query_mode not in self.query_mode_configs:
                raise ValueError(f"Unsupported query mode: {request.query_mode}")

            mode_config = self.query_mode_configs[request.query_mode]

            # Handle validation configuration
            validation_workflow = None
            validation_id = None
            validation_enabled = False

            if request.validation_config and request.validation_config.enabled:
                validation_workflow = await self.validation_service.create_workflow(
                    job_id, request.validation_config.dict()
                )
                validation_id = validation_workflow.validation_id
                validation_enabled = True
                logger.info(f"Validation enabled for job {job_id} with workflow {validation_id}")

            # Calculate complexity and processing time
            complexity = self._determine_complexity(request.query_mode)
            estimated_time = self._estimate_processing_time(request.query_mode, validation_enabled, validation_workflow)

            # Create job metadata
            job_metadata = self._create_job_metadata(request, mode_config, complexity, estimated_time,
                                                     validation_enabled, validation_id, validation_workflow)

            # Create job record
            job_tracker.create_job(
                job_id=job_id,
                job_type="llm_inference",
                metadata=job_metadata
            )

            # Start orchestration workflow
            await self.orchestration_service.start_query_workflow(
                job_id=job_id,
                request=request,
                validation_enabled=validation_enabled,
                validation_id=validation_id,
                validation_workflow=validation_workflow
            )

            return EnhancedBackgroundJobResponse(
                message=f"Query processing in '{mode_config['name']}' mode" +
                        (f" with {validation_workflow.validation_type.value} validation" if validation_enabled else ""),
                job_id=job_id,
                job_type="llm_inference",
                query_mode=request.query_mode,
                expected_processing_time=estimated_time,
                status="processing",
                complexity_level=complexity,
                validation_enabled=validation_enabled,
                validation_id=validation_id,
                validation_type=validation_workflow.validation_type if validation_workflow else None
            )

        except Exception as e:
            logger.error(f"Error processing query: {str(e)}")
            raise

    async def get_query_result(self, job_id: str) -> Optional[EnhancedQueryResponse]:
        """
        Get query results with integrated validation data.
        Moved from the router's get_query_result endpoint.
        """
        job_data = job_tracker.get_job(job_id)

        if not job_data:
            return None

        status = job_data.get("status", "")
        metadata = job_data.get("metadata", {})
        result = job_data.get("result", {})

        # Parse result if it's a JSON string
        if isinstance(result, str):
            try:
                result = json.loads(result)
            except:
                result = {"answer": result}

        # Get query mode
        query_mode = metadata.get("query_mode", "facts")
        try:
            query_mode_enum = QueryMode(query_mode)
        except ValueError:
            query_mode_enum = QueryMode.FACTS

        # Get validation workflow if it exists
        validation_workflow = None
        validation_summary = None
        validation_id = metadata.get("validation_id")

        if validation_id:
            validation_workflow = await self.validation_service.get_validation_workflow(validation_id)
            if validation_workflow:
                validation_summary = self._create_validation_summary(validation_workflow)

        if status == "completed":
            return await self._create_completed_response(result, metadata, query_mode_enum,
                                                         validation_workflow, validation_summary, job_id)
        elif status == "failed":
            return self._create_failed_response(job_data, query_mode_enum,
                                                validation_workflow, validation_summary, job_id)
        else:
            return self._create_processing_response(job_id, metadata, query_mode_enum,
                                                    validation_workflow, validation_summary)

    async def validate_query_compatibility(self, request: EnhancedQueryRequest) -> QueryValidationResult:
        """
        Validate query for mode compatibility and suggest validation type.
        Moved from validate_query_for_modes endpoint.
        """
        try:
            query_text = request.query.lower()

            # Mode compatibility scoring
            mode_scores = self._calculate_mode_compatibility_scores(query_text)

            # Find best matching mode
            suggested_mode = max(mode_scores.items(), key=lambda x: x[1])[0]
            confidence = max(mode_scores.values())

            # Create compatibility map
            compatibility_scores = {mode: score > 0.2 for mode, score in mode_scores.items()}

            # Determine validation recommendations
            validation_recommended, suggested_validation_type = self._determine_validation_recommendation(
                mode_scores, confidence
            )

            # Generate recommendations
            recommendations = self._generate_compatibility_recommendations(
                confidence, mode_scores, validation_recommended, suggested_validation_type
            )

            return QueryValidationResult(
                is_valid=True,
                mode_compatibility=compatibility_scores,
                recommendations=recommendations,
                suggested_mode=suggested_mode,
                confidence_score=confidence,
                suggested_validation_type=suggested_validation_type,
                validation_recommended=validation_recommended
            )

        except Exception as e:
            logger.error(f"Error validating query: {str(e)}")
            return QueryValidationResult(
                is_valid=False,
                mode_compatibility={},
                recommendations=["æŸ¥è¯¢éªŒè¯å¤±è´¥ï¼Œå°†ä½¿ç”¨é»˜è®¤çš„è½¦è¾†è§„æ ¼æŸ¥è¯¢æ¨¡å¼"],
                suggested_mode=QueryMode.FACTS,
                confidence_score=0.0,
                suggested_validation_type=ValidationType.BASIC,
                validation_recommended=True
            )

    def _determine_complexity(self, query_mode: QueryMode) -> str:
        """Determine query complexity based on mode."""
        complexity_map = {
            QueryMode.FACTS: "simple",
            QueryMode.FEATURES: "moderate",
            QueryMode.TRADEOFFS: "complex",
            QueryMode.SCENARIOS: "complex",
            QueryMode.DEBATE: "complex",
            QueryMode.QUOTES: "simple"
        }
        return complexity_map.get(query_mode, "simple")

    def _estimate_processing_time(self, query_mode: QueryMode, validation_enabled: bool,
                                  validation_workflow: Any) -> int:
        """Estimate processing time for the query."""
        base_times = {
            QueryMode.FACTS: 10,
            QueryMode.FEATURES: 30,
            QueryMode.TRADEOFFS: 45,
            QueryMode.SCENARIOS: 40,
            QueryMode.DEBATE: 50,
            QueryMode.QUOTES: 20
        }

        estimated_time = base_times.get(query_mode, 20)

        if validation_enabled and validation_workflow:
            validation_overhead = {
                ValidationType.BASIC: 5,
                ValidationType.COMPREHENSIVE: 15,
                ValidationType.USER_GUIDED: 10
            }
            estimated_time += validation_overhead.get(validation_workflow.validation_type, 5)

        return estimated_time

    def _create_job_metadata(self, request: EnhancedQueryRequest, mode_config: Dict[str, Any],
                             complexity: str, estimated_time: int, validation_enabled: bool,
                             validation_id: Optional[str], validation_workflow: Any) -> Dict[str, Any]:
        """Create comprehensive job metadata."""
        return {
            "query": request.query,
            "metadata_filter": request.metadata_filter,
            "top_k": request.top_k,
            "query_mode": request.query_mode.value,
            "has_custom_template": request.prompt_template is not None,
            "complexity_level": complexity,
            "estimated_time": estimated_time,
            "mode_name": mode_config["name"],
            "validation_enabled": validation_enabled,
            "validation_id": validation_id,
            "validation_type": validation_workflow.validation_type.value if validation_workflow else None,
            "unified_system": True
        }

    def _create_validation_summary(self, validation_workflow: Any) -> Dict[str, Any]:
        """Create validation summary for response."""
        return {
            "validation_id": validation_workflow.validation_id,
            "status": validation_workflow.overall_status.value,
            "type": validation_workflow.validation_type.value,
            "confidence": validation_workflow.overall_confidence,
            "passed": validation_workflow.validation_passed,
            "steps_completed": len([s for s in validation_workflow.steps if s.status.value == "completed"]),
            "total_steps": len(validation_workflow.steps),
            "awaiting_user_input": validation_workflow.awaiting_user_input,
            "current_step": validation_workflow.current_step.value if validation_workflow.current_step else None,
            "issues_identified": len(validation_workflow.issues_identified),
            "recommendations": len(validation_workflow.final_recommendations)
        }

    async def _create_completed_response(self, result: Dict[str, Any], metadata: Dict[str, Any],
                                         query_mode_enum: QueryMode, validation_workflow: Any,
                                         validation_summary: Optional[Dict], job_id: str) -> EnhancedQueryResponse:
        """Create response for completed jobs."""
        documents = result.get("documents", [])
        cleaned_documents = await self.document_service.clean_documents(documents)
        processing_stats = self.document_service.calculate_processing_statistics(documents)

        # Clean answer
        answer = self.response_service.clean_answer(result.get("answer", ""))

        # Parse structured sections for two-layer modes
        analysis_structure = None
        mode_config = self.query_mode_configs.get(query_mode_enum)
        if mode_config and mode_config.get("two_layer"):
            analysis_structure = self.response_service.parse_structured_answer(answer, query_mode_enum.value)

        mode_metadata = {
            "processing_mode": query_mode_enum.value,
            "complexity_level": metadata.get("complexity_level", "simple"),
            "mode_name": metadata.get("mode_name", ""),
            "processing_stats": processing_stats,
            "validation_enabled": metadata.get("validation_enabled", False),
            "unified_system": True
        }

        return EnhancedQueryResponse(
            query=result.get("query", metadata.get("query", "")),
            answer=answer,
            documents=cleaned_documents,
            query_mode=query_mode_enum,
            analysis_structure=analysis_structure,
            metadata_filters_used=metadata.get("metadata_filter"),
            execution_time=result.get("execution_time", 0),
            status="completed",
            job_id=job_id,
            mode_metadata=mode_metadata,
            validation=validation_workflow,
            validation_summary=validation_summary
        )

    def _create_failed_response(self, job_data: Dict[str, Any], query_mode_enum: QueryMode,
                                validation_workflow: Any, validation_summary: Optional[Dict],
                                job_id: str) -> EnhancedQueryResponse:
        """Create response for failed jobs."""
        metadata = job_data.get("metadata", {})
        error_msg = job_data.get('error', 'Unknown error')

        return EnhancedQueryResponse(
            query=metadata.get("query", ""),
            answer=f"Error: {error_msg}",
            documents=[],
            query_mode=query_mode_enum,
            metadata_filters_used=metadata.get("metadata_filter"),
            execution_time=0,
            status="failed",
            job_id=job_id,
            validation=validation_workflow,
            validation_summary=validation_summary
        )

    def _create_processing_response(self, job_id: str, metadata: Dict[str, Any],
                                    query_mode_enum: QueryMode, validation_workflow: Any,
                                    validation_summary: Optional[Dict]) -> EnhancedQueryResponse:
        """Create response for jobs still processing."""
        chain_status = job_chain.get_job_chain_status(job_id)
        progress_msg = "Processing query..."

        if chain_status:
            current_task = chain_status.get("current_task", "unknown")
            mode_name = metadata.get("mode_name", query_mode_enum.value)

            if validation_workflow and validation_workflow.awaiting_user_input:
                progress_msg = f"Awaiting user input for validation..."
            else:
                progress_msg = f"Processing {mode_name}... (Current: {current_task})"

        return EnhancedQueryResponse(
            query=metadata.get("query", ""),
            answer=progress_msg,
            documents=[],
            query_mode=query_mode_enum,
            metadata_filters_used=metadata.get("metadata_filter"),
            execution_time=0,
            status="processing",
            job_id=job_id,
            validation=validation_workflow,
            validation_summary=validation_summary
        )

    def _calculate_mode_compatibility_scores(self, query_text: str) -> Dict[QueryMode, float]:
        """Calculate compatibility scores for each query mode."""
        # Keywords for each mode
        facts_keywords = ["ä»€ä¹ˆ", "å¤šå°‘", "å“ªä¸ª", "è§„æ ¼", "å‚æ•°", "å°ºå¯¸", "é‡é‡"]
        features_keywords = ["åº”è¯¥", "å€¼å¾—", "å»ºè®®", "å¢åŠ ", "åŠŸèƒ½", "æ˜¯å¦"]
        tradeoffs_keywords = ["vs", "å¯¹æ¯”", "ä¼˜ç¼ºç‚¹", "åˆ©å¼Š", "æ¯”è¾ƒ", "é€‰æ‹©"]
        scenarios_keywords = ["åœºæ™¯", "æƒ…å†µä¸‹", "ä½¿ç”¨æ—¶", "ä½“éªŒ", "ç”¨æˆ·", "æ—¥å¸¸"]
        debate_keywords = ["è§‚ç‚¹", "çœ‹æ³•", "è®¤ä¸º", "è§’åº¦", "å›¢é˜Ÿ", "è®¨è®º"]
        quotes_keywords = ["è¯„ä»·", "åé¦ˆ", "è¯„è®º", "ç”¨æˆ·è¯´", "çœŸå®", "ä½“éªŒ"]

        # Calculate scores
        mode_scores = {
            QueryMode.FACTS: max(
                sum(1 for kw in facts_keywords if kw in query_text) / len(facts_keywords),
                0.4  # Default minimum for facts mode
            ),
            QueryMode.FEATURES: sum(1 for kw in features_keywords if kw in query_text) / len(features_keywords),
            QueryMode.TRADEOFFS: sum(1 for kw in tradeoffs_keywords if kw in query_text) / len(tradeoffs_keywords),
            QueryMode.SCENARIOS: sum(1 for kw in scenarios_keywords if kw in query_text) / len(scenarios_keywords),
            QueryMode.DEBATE: sum(1 for kw in debate_keywords if kw in query_text) / len(debate_keywords),
            QueryMode.QUOTES: sum(1 for kw in quotes_keywords if kw in query_text) / len(quotes_keywords)
        }

        return mode_scores

    def _determine_validation_recommendation(self, mode_scores: Dict[QueryMode, float],
                                             confidence: float) -> tuple[bool, Optional[ValidationType]]:
        """Determine if validation is recommended and what type."""
        validation_recommended = False
        suggested_validation_type = None

        if confidence < 0.6:
            validation_recommended = True
            suggested_validation_type = ValidationType.COMPREHENSIVE
        elif any(score > 0.3 for score in [
            mode_scores[QueryMode.FEATURES],
            mode_scores[QueryMode.TRADEOFFS],
            mode_scores[QueryMode.SCENARIOS]
        ]):
            validation_recommended = True
            suggested_validation_type = ValidationType.USER_GUIDED
        elif mode_scores[QueryMode.FACTS] > 0.6:
            suggested_validation_type = ValidationType.BASIC

        return validation_recommended, suggested_validation_type

    def _generate_compatibility_recommendations(self, confidence: float, mode_scores: Dict[QueryMode, float],
                                                validation_recommended: bool,
                                                suggested_validation_type: Optional[ValidationType]) -> List[str]:
        """Generate recommendations based on compatibility analysis."""
        recommendations = []

        if confidence < 0.4:
            recommendations.append("å»ºè®®ä½¿ç”¨è½¦è¾†è§„æ ¼æŸ¥è¯¢æ¨¡å¼ï¼ˆé»˜è®¤æ¨¡å¼ï¼‰")

        if validation_recommended:
            recommendations.append(f"å»ºè®®å¯ç”¨{suggested_validation_type.value}éªŒè¯ä»¥æé«˜ç­”æ¡ˆè´¨é‡")

        if mode_scores[QueryMode.FACTS] > 0.3:
            recommendations.append("æŸ¥è¯¢åŒ…å«å…·ä½“è§„æ ¼é—®é¢˜ï¼Œè½¦è¾†è§„æ ¼æŸ¥è¯¢æ¨¡å¼æœ€é€‚åˆ")

        return recommendations