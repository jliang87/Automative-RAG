import os
import streamlit as st
import httpx
from typing import Dict, List, Optional, Union
from src.ui.components import header, api_request

# é…ç½®åº”ç”¨
st.set_page_config(
    page_title="æ±½è½¦è§„æ ¼ RAG ç³»ç»Ÿ",
    page_icon="ğŸš—",
    layout="wide",
    initial_sidebar_state="expanded",
)

# API é…ç½®
API_URL = os.environ.get("API_URL", "http://localhost:8000")
API_KEY = os.environ.get("API_KEY", "default-api-key")

# ä¼šè¯çŠ¶æ€åˆå§‹åŒ–
if "api_url" not in st.session_state:
    st.session_state.api_url = API_URL
if "api_key" not in st.session_state:
    st.session_state.api_key = API_KEY
if "authenticated" not in st.session_state:
    st.session_state.authenticated = False

header(
    "æ±½è½¦è§„æ ¼ RAG ç³»ç»Ÿ",
    "ä¸€ä¸ªåŸºäº GPU åŠ é€Ÿçš„ç³»ç»Ÿï¼Œç”¨äºä½¿ç”¨å»¶è¿Ÿäº¤äº’æ£€ç´¢ (Late Interaction Retrieval) å’Œæ··åˆé‡æ’åºè¿›è¡Œæ±½è½¦è§„æ ¼ä¿¡æ¯æ£€ç´¢ã€‚"
)

# ç³»ç»Ÿæ¦‚è¿°
st.markdown("""
## å…³äºç³»ç»Ÿ

è¯¥ç³»ç»Ÿé‡‡ç”¨æœ€å…ˆè¿›çš„æ£€ç´¢å¢å¼ºç”Ÿæˆ (RAG) æŠ€æœ¯ï¼Œæä¾›ç²¾ç¡®çš„æ±½è½¦è§„æ ¼ä¿¡æ¯ã€‚ä¸»è¦ç‰¹æ€§åŒ…æ‹¬ï¼š

- **å¤šè¯­è¨€æ”¯æŒ**ï¼šä½¿ç”¨ BAAI/bge-m3 åµŒå…¥æ¨¡å‹ï¼ŒåŒæ—¶æ”¯æŒä¸­æ–‡å’Œè‹±æ–‡å†…å®¹
- **ä¸¤é˜¶æ®µæ··åˆé‡æ’åº**ï¼šç»“åˆ ColBERT å’Œ BGE-Reranker-Large å®ç°é«˜è´¨é‡æ£€ç´¢
  - ColBERT æä¾›ä»¤ç‰Œçº§åˆ«çš„ç²¾ç¡®äº¤äº’åˆ†æï¼ˆå æ¯” 80%ï¼‰
  - BGE-Reranker å¢å¼ºåŒè¯­ç†è§£èƒ½åŠ›ï¼ˆå æ¯” 20%ï¼‰
- **å»¶è¿Ÿäº¤äº’æ£€ç´¢**ï¼ˆColBERTï¼‰å®ç°æ›´ç²¾å‡†çš„è¯­ä¹‰åŒ¹é…
- **æœ¬åœ° DeepSeek LLM** æä¾›æ—  API ä¾èµ–çš„ç­”æ¡ˆç”Ÿæˆ
- **ç»Ÿä¸€è§†é¢‘å¤„ç†**ï¼šä½¿ç”¨ Whisper AI é«˜è´¨é‡è½¬å½• YouTubeã€Bilibili ç­‰å¹³å°è§†é¢‘
- **å…¨ GPU åŠ é€Ÿ**ï¼Œæ”¯æŒè½¬å½•ã€OCRã€åµŒå…¥å’Œæ¨ç†è®¡ç®—
- **æ··åˆæœç´¢** ç»“åˆå‘é‡ç›¸ä¼¼åº¦å’Œå…ƒæ•°æ®ç­›é€‰
- **åŒè¯­ OCR**ï¼šæ”¯æŒè‹±æ–‡å’Œç®€ä½“ä¸­æ–‡æ–‡æ¡£çš„å…‰å­¦å­—ç¬¦è¯†åˆ«
- **åå°å¤„ç†ç³»ç»Ÿ**ï¼šèµ„æºå¯†é›†å‹ä»»åŠ¡ï¼ˆå¦‚è§†é¢‘è½¬å½•å’ŒPDFå¤„ç†ï¼‰åœ¨åå°è¿è¡Œï¼Œæé«˜ç³»ç»Ÿå“åº”èƒ½åŠ›
""")

# æ·»åŠ æ–°çš„éƒ¨åˆ†ï¼šåå°å¤„ç†ç³»ç»Ÿä»‹ç»
st.markdown("""
## åå°å¤„ç†ç³»ç»Ÿ

ç³»ç»Ÿç°åœ¨åŒ…å«ä¸€ä¸ªå¼ºå¤§çš„åå°å¤„ç†å­ç³»ç»Ÿï¼Œä¸“é—¨å¤„ç†èµ„æºå¯†é›†å‹ä»»åŠ¡ï¼š

### ä¸»è¦ç‰¹ç‚¹

- **éé˜»å¡å¤„ç†**ï¼šè§†é¢‘è½¬å½•å’ŒPDFå¤„ç†ç­‰é‡ä»»åŠ¡åœ¨åå°æ‰§è¡Œï¼ŒUIä¿æŒå“åº”
- **ä»»åŠ¡ç®¡ç†**ï¼šå®Œæ•´çš„ä»»åŠ¡ç®¡ç†ç•Œé¢ï¼Œè·Ÿè¸ªæ‰€æœ‰å¤„ç†ä»»åŠ¡çš„çŠ¶æ€
- **é«˜å¹¶å‘æ”¯æŒ**ï¼šåŒæ—¶å¤„ç†å¤šä¸ªä»»åŠ¡ï¼Œå……åˆ†åˆ©ç”¨ç³»ç»Ÿèµ„æº
- **è‡ªåŠ¨èµ„æºç®¡ç†**ï¼šä¼˜åŒ–CPUå’Œå†…å­˜ä½¿ç”¨ï¼Œé˜²æ­¢ç³»ç»Ÿè¿‡è½½
- **ä»»åŠ¡æ¢å¤**ï¼šæ”¯æŒä»æ„å¤–ä¸­æ–­ä¸­æ¢å¤ä»»åŠ¡

### æ”¯æŒçš„åå°ä»»åŠ¡ç±»å‹

1. **è§†é¢‘å¤„ç†**ï¼šYouTubeå’ŒBilibiliè§†é¢‘çš„ä¸‹è½½å’Œè½¬å½•
2. **PDFå¤„ç†**ï¼šPDFè§£æã€OCRå’Œè¡¨æ ¼æå–
3. **æ‰¹é‡è§†é¢‘å¤„ç†**ï¼šä¸€æ¬¡å¤„ç†å¤šä¸ªè§†é¢‘é“¾æ¥

### å¦‚ä½•ä½¿ç”¨

1. æäº¤ä»»åŠ¡åï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨åˆ›å»ºä¸€ä¸ªåå°ä½œä¸šå¹¶è·³è½¬åˆ°ä»»åŠ¡ç®¡ç†é¡µé¢
2. åœ¨ä»»åŠ¡ç®¡ç†é¡µé¢æŸ¥çœ‹æ‰€æœ‰ä»»åŠ¡çš„çŠ¶æ€å’Œç»“æœ
""")

# è·å–ç³»ç»ŸçŠ¶æ€ä¿¡æ¯
try:
    status_info = api_request(
        endpoint="/ingest/status",
        method="GET"
    )

    if status_info:
        col1, col2 = st.columns(2)

        with col1:
            st.subheader("ç³»ç»ŸçŠ¶æ€")
            st.write(f"çŠ¶æ€: {status_info.get('status', 'æœªçŸ¥')}")
            document_count = status_info.get('document_count') or 0
            st.write(f"æ–‡æ¡£æ•°é‡: {document_count}")

            # æ˜¾ç¤ºé›†åˆä¿¡æ¯ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            collection = status_info.get("collection") or 'æœªå®šä¹‰'
            st.write(f"æ•°æ®é›†åˆ: {collection}")

            # æ˜¾ç¤ºåå°ä»»åŠ¡çŠ¶æ€ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if "job_stats" in status_info:
                job_stats = status_info.get("job_stats", {})
                st.subheader("åå°ä»»åŠ¡çŠ¶æ€")

                col1a, col1b, col1c, col1d = st.columns(4)
                with col1a:
                    st.metric("ç­‰å¾…ä¸­", job_stats.get("pending_jobs", 0))
                with col1b:
                    st.metric("å¤„ç†ä¸­", job_stats.get("processing_jobs", 0))
                with col1c:
                    st.metric("å·²å®Œæˆ", job_stats.get("completed_jobs", 0))
                with col1d:
                    st.metric("å¤±è´¥", job_stats.get("failed_jobs", 0))

                if job_stats.get("processing_jobs", 0) > 0 or job_stats.get("pending_jobs", 0) > 0:
                    st.info("æœ‰ä»»åŠ¡æ­£åœ¨å¤„ç†ä¸­! [å‰å¾€ä»»åŠ¡ç®¡ç†é¡µé¢æŸ¥çœ‹è¯¦æƒ…](#)")

        with col2:
            st.subheader("GPU ä¿¡æ¯")
            gpu_info = status_info.get("gpu_info", {})

            if gpu_info:
                st.write(f"è®¾å¤‡: {gpu_info.get('device', 'æœªçŸ¥')}")
                if 'device_name' in gpu_info:
                    st.write(f"GPU: {gpu_info['device_name']}")
                if 'memory_allocated' in gpu_info and gpu_info['memory_allocated'] is not None:
                    st.write(f"å·²ä½¿ç”¨å†…å­˜: {gpu_info['memory_allocated']}")
                else:
                    st.write("å·²ä½¿ç”¨å†…å­˜: æœªçŸ¥")
                if 'whisper_model' in gpu_info:
                    st.write(f"Whisper æ¨¡å‹: {gpu_info['whisper_model']}")
            else:
                st.write("è¿è¡Œåœ¨ CPU ä¸Š")

    # è·å– LLM ä¿¡æ¯
    llm_info = api_request(
        endpoint="/query/llm-info",
        method="GET"
    )

    if llm_info:
        st.subheader("LLM ä¿¡æ¯")

        # è§„èŒƒåŒ–æ¨¡å‹åç§°
        model_name = llm_info.get("model_name", "æœªçŸ¥")
        if "/" in model_name:
            model_name = model_name.split("/")[-1]

        col1, col2 = st.columns(2)

        with col1:
            st.write(f"æ¨¡å‹: {model_name}")
            st.write(f"é‡åŒ–æ–¹å¼: {llm_info.get('quantization', 'æ— ')}")

        with col2:
            st.write(f"æ¸©åº¦å‚æ•°: {llm_info.get('temperature', 0.0)}")
            st.write(f"æœ€å¤§ Token æ•°: {llm_info.get('max_tokens', 0)}")

        if 'vram_usage' in llm_info:
            st.write(f"æ˜¾å­˜å ç”¨: {llm_info['vram_usage']}")

except Exception as e:
    st.error(f"è·å–ç³»ç»Ÿä¿¡æ¯å‡ºé”™: {str(e)}")
