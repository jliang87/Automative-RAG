import os
import streamlit as st
import httpx
from typing import Dict, List, Optional, Union
from src.ui.components import header, api_request

# é…ç½®åº”ç”¨
st.set_page_config(
    page_title="æ±½è½¦è§„æ ¼ RAG ç³»ç»Ÿ",
    page_icon="ğŸš—",
    layout="wide",
    initial_sidebar_state="expanded",
)

# API é…ç½®
API_URL = os.environ.get("API_URL", "http://localhost:8000")
API_KEY = os.environ.get("API_KEY", "default-api-key")

# ä¼šè¯çŠ¶æ€åˆå§‹åŒ–
if "api_key" not in st.session_state:
    st.session_state.api_key = API_KEY
if "authenticated" not in st.session_state:
    st.session_state.authenticated = False
if "current_page" not in st.session_state:
    st.session_state.current_page = "query"


def make_api_request(
        endpoint: str,
        method: str = "GET",
        data: Optional[Dict] = None,
        files: Optional[Dict] = None,
        params: Optional[Dict] = None,
) -> httpx.Response:
    """å‘ API å‘é€è¯·æ±‚"""
    headers = {"x-token": st.session_state.api_key}
    url = f"{API_URL}{endpoint}"

    try:
        with httpx.Client() as client:
            if method == "GET":
                response = client.get(url, headers=headers, params=params)
            elif method == "POST":
                if files:
                    response = client.post(url, headers=headers, data=data, files=files)
                else:
                    response = client.post(url, headers=headers, json=data)
            elif method == "DELETE":
                response = client.delete(url, headers=headers)
            else:
                st.error(f"ä¸æ”¯æŒçš„è¯·æ±‚æ–¹æ³•: {method}")
                return None

            return response
    except Exception as e:
        st.error(f"API è¯·æ±‚å‡ºé”™: {str(e)}")
        return None

header(
    "æ±½è½¦è§„æ ¼ RAG ç³»ç»Ÿ",
    "ä¸€ä¸ªåŸºäº GPU åŠ é€Ÿçš„ç³»ç»Ÿï¼Œç”¨äºä½¿ç”¨åæœŸäº¤äº’å¼æ£€ç´¢ (Late Interaction Retrieval) è¿›è¡Œæ±½è½¦è§„æ ¼ä¿¡æ¯æ£€ç´¢ã€‚"
)

# ç³»ç»Ÿæ¦‚è¿°
st.markdown("""
## å…³äºç³»ç»Ÿ

è¯¥ç³»ç»Ÿé‡‡ç”¨æœ€å…ˆè¿›çš„æ£€ç´¢å¢å¼ºç”Ÿæˆ (RAG) æŠ€æœ¯ï¼Œæä¾›ç²¾ç¡®çš„æ±½è½¦è§„æ ¼ä¿¡æ¯ã€‚ä¸»è¦ç‰¹æ€§åŒ…æ‹¬ï¼š

- **åæœŸäº¤äº’æ£€ç´¢**ï¼ˆColBERTï¼‰å®ç°æ›´ç²¾å‡†çš„è¯­ä¹‰åŒ¹é…
- **æœ¬åœ° DeepSeek LLM** æä¾›æ—  API ä¾èµ–çš„ç­”æ¡ˆç”Ÿæˆ
- **å¤šæ¨¡æ€è¾“å…¥å¤„ç†** æ”¯æŒ YouTubeã€Bilibiliã€ä¼˜é…·è§†é¢‘å’Œ PDF æ–‡æ¡£
- **å…¨ GPU åŠ é€Ÿ**ï¼Œæ”¯æŒè½¬å½•ã€OCRã€åµŒå…¥å’Œæ¨ç†è®¡ç®—
- **æ··åˆæœç´¢** ç»“åˆå‘é‡ç›¸ä¼¼åº¦å’Œå…ƒæ•°æ®ç­›é€‰
""")

# è·å–ç³»ç»ŸçŠ¶æ€ä¿¡æ¯
try:
    status_info = api_request(
        endpoint="/ingest/status",
        method="GET"
    )

    if status_info:
        col1, col2 = st.columns(2)

        with col1:
            st.subheader("ç³»ç»ŸçŠ¶æ€")
            st.write(f"çŠ¶æ€: {status_info.get('status', 'æœªçŸ¥')}")
            st.write(f"æ–‡æ¡£æ•°é‡: {status_info.get('document_count', 0):,}")

            # æ˜¾ç¤ºé›†åˆä¿¡æ¯ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if "collection" in status_info:
                st.write(f"æ•°æ®é›†åˆ: {status_info['collection']}")

        with col2:
            st.subheader("GPU ä¿¡æ¯")
            gpu_info = status_info.get("gpu_info", {})

            if gpu_info:
                st.write(f"è®¾å¤‡: {gpu_info.get('device', 'æœªçŸ¥')}")
                if 'device_name' in gpu_info:
                    st.write(f"GPU: {gpu_info['device_name']}")
                if 'memory_allocated' in gpu_info:
                    st.write(f"å·²ä½¿ç”¨å†…å­˜: {gpu_info['memory_allocated']}")
                if 'whisper_model' in gpu_info:
                    st.write(f"Whisper æ¨¡å‹: {gpu_info['whisper_model']}")
            else:
                st.write("è¿è¡Œåœ¨ CPU ä¸Š")

    # è·å– LLM ä¿¡æ¯
    llm_info = api_request(
        endpoint="/query/llm-info",
        method="GET"
    )

    if llm_info:
        st.subheader("LLM ä¿¡æ¯")

        # è§„èŒƒåŒ–æ¨¡å‹åç§°
        model_name = llm_info.get("model_name", "æœªçŸ¥")
        if "/" in model_name:
            model_name = model_name.split("/")[-1]

        col1, col2 = st.columns(2)

        with col1:
            st.write(f"æ¨¡å‹: {model_name}")
            st.write(f"é‡åŒ–æ–¹å¼: {llm_info.get('quantization', 'æ— ')}")

        with col2:
            st.write(f"æ¸©åº¦å‚æ•°: {llm_info.get('temperature', 0.0)}")
            st.write(f"æœ€å¤§ Token æ•°: {llm_info.get('max_tokens', 0)}")

        if 'vram_usage' in llm_info:
            st.write(f"æ˜¾å­˜å ç”¨: {llm_info['vram_usage']}")

except Exception as e:
    st.error(f"è·å–ç³»ç»Ÿä¿¡æ¯å‡ºé”™: {str(e)}")

# ä½¿ç”¨æŒ‡å—
st.markdown("""
## å…¥é—¨æŒ‡å—

1. **æ•°æ®å¯¼å…¥**ï¼šè¿›å…¥â€œæ•°æ®å¯¼å…¥â€é€‰é¡¹å¡ï¼Œä¸Šä¼ æ±½è½¦ç›¸å…³æ•°æ®ï¼š
   - YouTube æ±½è½¦è¯„æµ‹ä¸å±•ç¤ºè§†é¢‘
   - Bilibili æ±½è½¦å†…å®¹
   - ä¼˜é…·æ±½è½¦è§†é¢‘
   - PDF è§„æ ¼ä¹¦å’Œè¯´æ˜ä¹¦
   - æ‰‹åŠ¨å½•å…¥æ±½è½¦è§„æ ¼æ•°æ®

2. **æŸ¥è¯¢æ•°æ®**ï¼šè¿›å…¥â€œæŸ¥è¯¢â€é€‰é¡¹å¡ï¼Œæé—®æ±½è½¦ç›¸å…³é—®é¢˜ï¼š
   - æŒ‰ **å“ç‰Œã€è½¦å‹ã€å¹´ä»½ã€ç±»åˆ«ç­‰** ç­›é€‰
   - ç²¾ç¡®å›ç­”å¹¶æä¾›æ•°æ®æ¥æº
   - æ˜¾ç¤ºçŸ¥è¯†åº“ä¸­çš„ç›¸å…³ç‰‡æ®µ

3. **ç¤ºä¾‹æŸ¥è¯¢**ï¼š
   - "2023 æ¬¾ä¸°ç”°å‡¯ç¾ç‘çš„é©¬åŠ›æ˜¯å¤šå°‘ï¼Ÿ"
   - "æœ¬ç”°æ€åŸŸå’Œä¸°ç”°å¡ç½—æ‹‰çš„æ²¹è€—å¯¹æ¯”"
   - "ç¦ç‰¹ F-150 çš„è½¦èº«å°ºå¯¸æ˜¯å¤šå°‘ï¼Ÿ"
   - "ç‰¹æ–¯æ‹‰ Model 3 çš„æ ‡é…å®‰å…¨åŠŸèƒ½æœ‰å“ªäº›ï¼Ÿ"
""")

# ç³»ç»Ÿæ¶æ„
with st.expander("ç³»ç»Ÿæ¶æ„"):
    st.markdown("""
    ### ä¸»è¦ç»„ä»¶

    1. **æ•°æ®å¯¼å…¥ç®¡é“**
       - è§†é¢‘è½¬å½•ï¼ˆYouTubeã€Bilibiliã€ä¼˜é…·ï¼‰ä½¿ç”¨ Whisper
       - PDF è§£æï¼ˆOCR å’Œè¡¨æ ¼æå–ï¼‰
       - å…ƒæ•°æ®æå–ä¸æ–‡æ¡£åˆ‡åˆ†

    2. **å‘é‡æ•°æ®åº“**
       - Qdrant é«˜æ•ˆå­˜å‚¨å‘é‡
       - æ··åˆæœç´¢èƒ½åŠ›ï¼ˆå‘é‡ + å…ƒæ•°æ®ï¼‰
       - æ–‡æ¡£å­˜å‚¨ä¸ç®¡ç†

    3. **æ£€ç´¢ç³»ç»Ÿ**
       - Qdrant è¿›è¡Œåˆæ­¥æ£€ç´¢
       - ColBERT è¿›è¡Œè¯­ä¹‰é‡æ’åº
       - é‡‡ç”¨åæœŸäº¤äº’æ¨¡å¼è¿›è¡Œ Token çº§åˆ†æ

    4. **ç”Ÿæˆå±‚**
       - DeepSeek LLM é›†æˆ
       - ç»“åˆä¸Šä¸‹æ–‡ä¿¡æ¯ç”Ÿæˆç­”æ¡ˆ
       - å“åº”å¸¦æœ‰æ¥æºå¼•ç”¨

    5. **API å±‚**
       - FastAPI åç«¯ï¼Œé‡‡ç”¨ä¾èµ–æ³¨å…¥
       - Swagger æ–‡æ¡£
       - è®¤è¯ä¸å®‰å…¨

    6. **ç”¨æˆ·ç•Œé¢**
       - Streamlit å¯è§†åŒ–ç•Œé¢
       - æŸ¥è¯¢ä¸ç­›é€‰æ¥å£
       - ç»“æœå±•ç¤º
       - ç»“æœæ¥æºæ ‡æ³¨ä¸è§£é‡Š
    """)
