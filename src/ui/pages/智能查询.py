import streamlit as st
import time
import json
from typing import Dict, Any, Optional
from src.ui.api_client import api_request
from src.ui.session_init import initialize_session_state

# UPDATED: Import unified validation display instead of separate components
from src.ui.components.validation_display import (
    render_unified_validation_display,
    render_quick_validation_badge,
    render_validation_help,
    render_real_time_validation_feedback
)
from src.ui.components.metadata_display import (
    render_embedded_metadata_display,
    render_metadata_summary_card,
    add_metadata_display_to_sources,
    EmbeddedMetadataExtractor
)

initialize_session_state()

# Query mode configurations (simplified)
QUERY_MODES = {
    "facts": {
        "icon": "ğŸ“Œ",
        "name": "è½¦è¾†ä¿¡æ¯æ€»è§ˆ",
        "description": "æŸ¥è¯¢è½¦è¾†çš„å„ç±»ä¿¡æ¯å’Œå‚æ•°",
        "two_layer": True,
        "is_default": True,
        "examples": [
            "2023å¹´å®é©¬X5çš„åå¤‡ç®±å®¹ç§¯æ˜¯å¤šå°‘ï¼Ÿ",
            "ç‰¹æ–¯æ‹‰Model 3çš„åˆ¹è½¦æ€§èƒ½æ€ä¹ˆæ ·ï¼Ÿ",
            "å¥”é©°Eçº§æœ‰å“ªäº›å®‰å…¨é…ç½®ï¼Ÿ"
        ],
        "validation_priority": "high"  # High priority for validation display
    },
    "features": {
        "icon": "ğŸ’¡",
        "name": "åŠŸèƒ½å»ºè®®",
        "description": "è¯„ä¼°æ˜¯å¦åº”è¯¥æ·»åŠ æŸé¡¹åŠŸèƒ½",
        "two_layer": True,
        "examples": [
            "æ˜¯å¦åº”è¯¥ä¸ºç”µåŠ¨è½¦å¢åŠ æ°›å›´ç¯åŠŸèƒ½ï¼Ÿ",
            "å¢åŠ æ¨¡æ‹Ÿå¼•æ“å£°éŸ³å¯¹ç”¨æˆ·ä½“éªŒçš„å½±å“",
            "ARæŠ¬å¤´æ˜¾ç¤ºå™¨å€¼å¾—æŠ•èµ„å—ï¼Ÿ"
        ],
        "validation_priority": "medium"
    },
    "tradeoffs": {
        "icon": "âš–ï¸",
        "name": "æƒè¡¡åˆ†æ",
        "description": "åˆ†æè®¾è®¡é€‰æ‹©çš„ä¼˜ç¼ºç‚¹",
        "two_layer": True,
        "examples": [
            "ä½¿ç”¨æ¨¡æ‹Ÿå£°éŸ³ vs è‡ªç„¶é™éŸ³çš„åˆ©å¼Š",
            "ç§»é™¤ç‰©ç†æŒ‰é”®çš„ä¼˜ç¼ºç‚¹åˆ†æ",
            "å¤§å±å¹• vs ä¼ ç»Ÿä»ªè¡¨ç›˜çš„å¯¹æ¯”"
        ],
        "validation_priority": "medium"
    },
    "scenarios": {
        "icon": "ğŸ§©",
        "name": "åœºæ™¯åˆ†æ",
        "description": "è¯„ä¼°åŠŸèƒ½åœ¨å®é™…ä½¿ç”¨åœºæ™¯ä¸­çš„è¡¨ç°",
        "two_layer": True,
        "examples": [
            "é•¿é€”æ—…è¡Œæ—¶è¿™ä¸ªåŠŸèƒ½å¦‚ä½•è¡¨ç°ï¼Ÿ",
            "å®¶åº­ç”¨æˆ·åœ¨æ—¥å¸¸é€šå‹¤ä¸­çš„ä½“éªŒå¦‚ä½•ï¼Ÿ",
            "å¯’å†·æ°”å€™ä¸‹çš„æ€§èƒ½è¡¨ç°åˆ†æ"
        ],
        "validation_priority": "medium"
    },
    "debate": {
        "icon": "ğŸ—£ï¸",
        "name": "å¤šè§’è‰²è®¨è®º",
        "description": "æ¨¡æ‹Ÿä¸åŒè§’è‰²çš„è§‚ç‚¹å’Œè®¨è®º",
        "two_layer": False,
        "examples": [
            "äº§å“ç»ç†ã€å·¥ç¨‹å¸ˆå’Œç”¨æˆ·ä»£è¡¨å¦‚ä½•çœ‹å¾…è‡ªåŠ¨é©¾é©¶åŠŸèƒ½ï¼Ÿ",
            "ä¸åŒå›¢é˜Ÿå¯¹ç”µæ± æŠ€æœ¯è·¯çº¿çš„è§‚ç‚¹",
            "å…³äºè½¦å†…ç©ºé—´è®¾è®¡çš„å¤šæ–¹è®¨è®º"
        ],
        "validation_priority": "low"
    },
    "quotes": {
        "icon": "ğŸ”",
        "name": "ç”¨æˆ·è¯„è®º",
        "description": "æå–ç›¸å…³çš„ç”¨æˆ·è¯„è®ºå’Œåé¦ˆ",
        "two_layer": False,
        "examples": [
            "ç”¨æˆ·å¯¹ç»­èˆªé‡Œç¨‹çš„çœŸå®è¯„ä»·",
            "å…³äºå†…é¥°è´¨é‡çš„ç”¨æˆ·åé¦ˆ",
            "å……ç”µä½“éªŒçš„ç”¨æˆ·è¯„è®ºæ‘˜å½•"
        ],
        "validation_priority": "low"
    }
}


def submit_unified_query(query_text: str, mode: str, filters: Optional[Dict] = None) -> Optional[str]:
    """Submit unified query with enhanced error handling."""
    try:
        unified_data = {
            "query": query_text,
            "metadata_filter": filters,
            "top_k": 8,
            "query_mode": mode,
            "prompt_template": None
        }

        result = api_request(
            endpoint="/query",
            method="POST",
            data=unified_data
        )

        if result and "job_id" in result:
            return result["job_id"]
        else:
            st.error("æŸ¥è¯¢æäº¤å¤±è´¥ï¼šæœåŠ¡å™¨æœªè¿”å›æœ‰æ•ˆå“åº”")
            return None

    except Exception as e:
        st.error(f"æŸ¥è¯¢æäº¤æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
        return None


def get_query_result(job_id: str) -> Optional[Dict]:
    """Get unified query results with enhanced error handling."""
    try:
        return api_request(f"/query/results/{job_id}", method="GET")
    except Exception as e:
        st.error(f"è·å–æŸ¥è¯¢ç»“æœæ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
        return None


def display_enhanced_results(result: Dict[str, Any], mode: str):
    """Display results with unified validation system."""

    answer = result.get("answer", "")
    if not answer:
        st.warning("æœªè·å¾—æŸ¥è¯¢ç»“æœ")
        return

    # Main answer display
    st.markdown("### ğŸ“‹ åˆ†æç»“æœ")

    # UPDATED: Quick validation badge at the top using unified system
    validation_badge = render_quick_validation_badge(result)
    st.markdown(f"**éªŒè¯çŠ¶æ€**: {validation_badge}")

    # Display the answer based on mode
    mode_info = QUERY_MODES.get(mode, {})

    if mode_info.get("two_layer"):
        display_two_layer_result(result, mode)
    elif mode == "debate":
        display_debate_result(answer)
    elif mode == "quotes":
        display_quotes_result(answer)
    else:
        st.markdown(answer)

    validation_priority = mode_info.get("validation_priority", "medium")

    if validation_priority in ["high", "medium"]:
        st.markdown("---")
        # Check if we're about to enter an expander context
        # We'll modify the validation display to be aware of the sources display
        render_unified_validation_display(result)

        # Enhanced sources display - pass context that we might be in expander
        display_enhanced_sources(result, in_expander=False)
    else:
        # For low priority modes, just show sources normally
        display_enhanced_sources(result, in_expander=False)


def display_two_layer_result(result: Dict[str, Any], mode: str):
    """Display results with two-layer structure for enhanced modes."""
    answer = result.get("answer", "")
    analysis_structure = result.get("analysis_structure")

    if analysis_structure and isinstance(analysis_structure, dict):
        if mode == "facts":
            if "ã€å®è¯åˆ†æã€‘" in analysis_structure:
                st.subheader("ğŸ“Š åŸºäºæ–‡æ¡£çš„å®è¯åˆ†æ")
                with st.container():
                    st.info(analysis_structure["ã€å®è¯åˆ†æã€‘"])

            if "ã€ç­–ç•¥æ¨ç†ã€‘" in analysis_structure:
                st.subheader("ğŸ§  ä¸“ä¸šæ¨ç†è¡¥å……")
                with st.container():
                    st.warning(analysis_structure["ã€ç­–ç•¥æ¨ç†ã€‘"])
                    st.caption("âš ï¸ æ­¤éƒ¨åˆ†ä¸ºAIæ¨ç†ï¼Œè¯·ç»“åˆå®è¯åˆ†æå‚è€ƒ")

        elif mode == "features":
            if "ã€å®è¯åˆ†æã€‘" in analysis_structure:
                st.subheader("ğŸ“Š æ–‡æ¡£å®è¯åˆ†æ")
                st.info(analysis_structure["ã€å®è¯åˆ†æã€‘"])

            if "ã€ç­–ç•¥æ¨ç†ã€‘" in analysis_structure:
                st.subheader("ğŸ’¡ åŠŸèƒ½ç­–ç•¥æ¨ç†")
                st.success(analysis_structure["ã€ç­–ç•¥æ¨ç†ã€‘"])

        elif mode == "tradeoffs":
            if "ã€æ–‡æ¡£æ”¯æ’‘ã€‘" in analysis_structure:
                st.subheader("ğŸ“‹ æ–‡æ¡£æ”¯æ’‘ä¿¡æ¯")
                st.info(analysis_structure["ã€æ–‡æ¡£æ”¯æ’‘ã€‘"])

            if "ã€åˆ©å¼Šåˆ†æã€‘" in analysis_structure:
                st.subheader("âš–ï¸ æƒè¡¡åˆ©å¼Šåˆ†æ")
                st.warning(analysis_structure["ã€åˆ©å¼Šåˆ†æã€‘"])

        elif mode == "scenarios":
            if "ã€æ–‡æ¡£åœºæ™¯ã€‘" in analysis_structure:
                st.subheader("ğŸ“– æ–‡æ¡£åœºæ™¯ä¿¡æ¯")
                st.info(analysis_structure["ã€æ–‡æ¡£åœºæ™¯ã€‘"])

            if "ã€åœºæ™¯æ¨ç†ã€‘" in analysis_structure:
                st.subheader("ğŸ¯ åœºæ™¯åº”ç”¨æ¨ç†")
                st.success(analysis_structure["ã€åœºæ™¯æ¨ç†ã€‘"])
        else:
            st.markdown(answer)
    else:
        st.markdown("**ğŸ“‹ åˆ†æç»“æœ:**")
        st.info(answer)


def display_debate_result(answer: str):
    """Display debate-style results with multiple perspectives."""
    st.subheader("ğŸ—£ï¸ å¤šè§’è‰²è®¨è®º")

    roles = ["äº§å“ç»ç†è§‚ç‚¹", "å·¥ç¨‹å¸ˆè§‚ç‚¹", "ç”¨æˆ·ä»£è¡¨è§‚ç‚¹"]
    sections = {}

    current_role = None
    current_content = []

    lines = answer.split('\n')

    for line in lines:
        line = line.strip()

        found_role = None
        for role in roles:
            if role in line or f"**{role}" in line:
                found_role = role
                break

        if found_role:
            if current_role and current_content:
                sections[current_role] = '\n'.join(current_content).strip()

            current_role = found_role
            current_content = []
        elif current_role and line:
            current_content.append(line)

    if current_role and current_content:
        sections[current_role] = '\n'.join(current_content).strip()

    role_icons = {
        "äº§å“ç»ç†è§‚ç‚¹": "ğŸ‘”",
        "å·¥ç¨‹å¸ˆè§‚ç‚¹": "ğŸ”§",
        "ç”¨æˆ·ä»£è¡¨è§‚ç‚¹": "ğŸ‘¥"
    }

    if sections:
        for role, content in sections.items():
            if content:
                icon = role_icons.get(role, "ğŸ’¬")
                st.markdown(f"### {icon} {role}")
                st.markdown(content)
                st.markdown("---")
    else:
        st.markdown(answer)


def display_quotes_result(answer: str):
    """Display user quotes in a structured format."""
    st.subheader("ğŸ’¬ ç”¨æˆ·è¯„è®ºæ‘˜å½•")

    import re
    quote_pattern = r'ã€æ¥æº\d+ã€‘[ï¼š:]"([^"]+)"'
    quotes = re.findall(quote_pattern, answer)

    if quotes:
        for i, quote in enumerate(quotes, 1):
            with st.container():
                st.markdown(f"**æ¥æº {i}:**")
                st.quote(quote)
                st.markdown("")
    else:
        st.markdown(answer)


def display_enhanced_sources(result: Dict[str, Any], in_expander: bool = False):
    """Display sources with enhanced validation and metadata analysis."""

    documents = result.get("documents", [])
    if not documents:
        return

    st.markdown("---")
    st.subheader(f"ğŸ“š å‚è€ƒæ¥æº ({len(documents)} ä¸ª)")

    # Add metadata quality overview
    st.markdown("#### ğŸ” å…ƒæ•°æ®è´¨é‡æ¦‚è§ˆ")
    quality_col1, quality_col2, quality_col3, quality_col4 = st.columns(4)

    # Analyze metadata quality across all documents
    extractor = EmbeddedMetadataExtractor()
    total_docs = len(documents)
    docs_with_embedded = 0
    docs_with_vehicle = 0
    avg_metadata_injection = 0

    for doc in documents:
        content = doc.get("content", "")
        metadata = doc.get("metadata", {})

        embedded_metadata, _ = extractor.extract_embedded_metadata(content)
        if embedded_metadata:
            docs_with_embedded += 1

        if metadata.get('has_vehicle_info'):
            docs_with_vehicle += 1

        if metadata.get('metadata_injected'):
            avg_metadata_injection += 1

    with quality_col1:
        st.metric("å«åµŒå…¥å…ƒæ•°æ®", f"{docs_with_embedded}/{total_docs}")

    with quality_col2:
        st.metric("è½¦è¾†ä¿¡æ¯æ£€æµ‹", f"{docs_with_vehicle}/{total_docs}")

    with quality_col3:
        injection_rate = (avg_metadata_injection / total_docs * 100) if total_docs > 0 else 0
        st.metric("æ³¨å…¥æˆåŠŸç‡", f"{injection_rate:.0f}%")

    with quality_col4:
        if docs_with_embedded > total_docs * 0.8:
            st.success("è´¨é‡ä¼˜ç§€")
        elif docs_with_embedded > total_docs * 0.5:
            st.warning("è´¨é‡è‰¯å¥½")
        else:
            st.error("è´¨é‡å¾…æ”¹è¿›")

    # Only create expander if we're not already inside one
    if not in_expander:
        with st.expander("æŸ¥çœ‹æ‰€æœ‰æ¥æºåŠå…ƒæ•°æ®", expanded=False):
            _render_sources_content_with_metadata(documents)
    else:
        _render_sources_content_with_metadata(documents)


def _render_sources_content_with_metadata(documents):
    """Render the actual sources content with metadata display."""

    for i, doc in enumerate(documents):
        metadata = doc.get("metadata", {})
        relevance = doc.get("relevance_score", 0)

        # Enhanced source display with validation status
        title = metadata.get("title", f"æ–‡æ¡£ {i + 1}")
        source_type = metadata.get("source", "unknown")

        # Source quality indicator with metadata awareness
        extractor = EmbeddedMetadataExtractor()
        embedded_metadata, _ = extractor.extract_embedded_metadata(doc.get("content", ""))
        has_good_metadata = len(embedded_metadata) > 2  # Has substantial metadata

        validation_status = metadata.get("validation_status", "unknown")
        automotive_warnings = metadata.get("automotive_warnings", [])

        # Enhanced quality assessment
        if validation_status == "validated" and relevance > 0.8 and has_good_metadata:
            st.success(f"**æ¥æº {i + 1}** ğŸŸ¢: {title[:60]}...")
            st.caption("âœ… é«˜è´¨é‡æ¥æºï¼Œå·²é€šè¿‡éªŒè¯ï¼Œå…ƒæ•°æ®å®Œæ•´")
        elif validation_status == "has_warnings" or automotive_warnings:
            st.warning(f"**æ¥æº {i + 1}** ğŸŸ¡: {title[:60]}...")
            st.caption("âš ï¸ åŒ…å«éœ€æ³¨æ„ä¿¡æ¯ï¼Œè¯·å‚è€ƒéªŒè¯è¯¦æƒ…")
        elif relevance > 0.6 and has_good_metadata:
            st.info(f"**æ¥æº {i + 1}** ğŸŸ¡: {title[:60]}...")
            st.caption("ğŸ“‹ ä¸­ç­‰è´¨é‡æ¥æºï¼Œå…ƒæ•°æ®è¾ƒå¥½")
        elif has_good_metadata:
            st.info(f"**æ¥æº {i + 1}** ğŸ”µ: {title[:60]}...")
            st.caption("ğŸ“Š å…ƒæ•°æ®ä¸°å¯Œï¼Œä½†ç›¸å…³åº¦ä¸€èˆ¬")
        else:
            st.error(f"**æ¥æº {i + 1}** ğŸ”´: {title[:60]}...")
            st.caption("â— ä½è´¨é‡æ¥æºï¼Œå…ƒæ•°æ®ç¼ºå¤±")

        # Basic source details
        col1, col2 = st.columns([1, 1])
        with col1:
            st.caption(f"**æ¥æºç±»å‹**: {source_type}")
            st.caption(f"**ç›¸å…³åº¦**: {relevance:.1%}")
        with col2:
            if metadata.get("author"):
                st.caption(f"**ä½œè€…**: {metadata['author']}")
            if metadata.get("published_date"):
                st.caption(f"**å‘å¸ƒ**: {metadata['published_date']}")

        # Show validation warnings
        if automotive_warnings:
            st.caption("âš ï¸ **éªŒè¯æé†’**:")
            for warning in automotive_warnings[:2]:
                st.caption(f"  â€¢ {warning}")
            if len(automotive_warnings) > 2:
                st.caption(f"  â€¢ è¿˜æœ‰ {len(automotive_warnings) - 2} é¡¹æé†’...")

            # NEW: Add metadata summary card
            st.markdown("**ğŸ·ï¸ å…ƒæ•°æ®æ‘˜è¦:**")
            # FIXED: Add unique_id to prevent key conflicts
            unique_id = f"query_source_{i}"
            render_metadata_summary_card(doc, compact=True, unique_id=unique_id)

        # Content and detailed metadata display
        if doc.get("content"):
            button_key = f"btn_show_content_{i}"
            metadata_key = f"btn_show_metadata_{i}"
            state_key = f"content_visible_{i}"
            metadata_state_key = f"metadata_visible_{i}"

            # Buttons for content and metadata
            btn_col1, btn_col2 = st.columns(2)

            with btn_col1:
                if st.button(f"æŸ¥çœ‹æ¥æº {i + 1} å†…å®¹", key=button_key):
                    current_state = st.session_state.get(state_key, False)
                    st.session_state[state_key] = not current_state
                    st.rerun()

            with btn_col2:
                if st.button(f"æŸ¥çœ‹æ¥æº {i + 1} è¯¦ç»†å…ƒæ•°æ®", key=metadata_key):
                    current_state = st.session_state.get(metadata_state_key, False)
                    st.session_state[metadata_state_key] = not current_state
                    st.rerun()

            # Show content if state is True
            if st.session_state.get(state_key, False):
                content_preview = doc['content'][:300] + "..." if len(doc['content']) > 300 else doc['content']
                st.text_area(
                    f"æ¥æº {i + 1} å†…å®¹é¢„è§ˆ",
                    content_preview,
                    height=100,
                    disabled=True,
                    key=f"content_display_{i}"
                )

                # Show detailed metadata if state is True
                if st.session_state.get(metadata_state_key, False):
                    with st.container():
                        # FIXED: Add unique_id to prevent key conflicts
                        unique_id = f"query_metadata_{i}"
                        render_embedded_metadata_display(doc, show_full_content=False, unique_id=unique_id)

        st.markdown("---")
        

# Main interface
st.title("ğŸ§  æ™ºèƒ½æŸ¥è¯¢")
st.markdown("å¸¦æœ‰ä¸“ä¸šéªŒè¯çš„ç»Ÿä¸€æŸ¥è¯¢å¹³å°")

# System status check
try:
    health_response = api_request("/health", silent=True, timeout=3.0)
    if not health_response or health_response.get("status") != "healthy":
        st.warning("âš ï¸ ç³»ç»ŸçŠ¶æ€å¼‚å¸¸ï¼ŒæŸ¥è¯¢ç»“æœå¯èƒ½ä¸å‡†ç¡®")
except:
    st.error("âŒ æ— æ³•è¿æ¥åˆ°æœåŠ¡å™¨ï¼Œè¯·ç¨åé‡è¯•")
    st.stop()

# Mode selection
st.subheader("ğŸ“‹ é€‰æ‹©æŸ¥è¯¢æ¨¡å¼")

if 'selected_mode' not in st.session_state:
    st.session_state.selected_mode = "facts"

if hasattr(st.session_state, 'smart_mode'):
    st.session_state.selected_mode = st.session_state.smart_mode
    del st.session_state.smart_mode

# Display modes in a grid with validation indicators
mode_cols = st.columns(3)

for i, (mode_key, mode_info) in enumerate(QUERY_MODES.items()):
    col = mode_cols[i % 3]

    with col:
        is_selected = st.session_state.get('selected_mode') == mode_key
        button_type = "primary" if is_selected else "secondary"

        # UPDATED: Add validation priority indicator
        validation_indicator = ""
        if mode_info.get("validation_priority") == "high":
            validation_indicator = " ğŸ›¡ï¸"
        elif mode_info.get("validation_priority") == "medium":
            validation_indicator = " ğŸ”"

        button_text = f"{mode_info['icon']} {mode_info['name']}{validation_indicator}"
        if is_selected:
            button_text = f"âœ… {button_text}"

        if st.button(
                button_text,
                key=f"mode_{mode_key}",
                use_container_width=True,
                help=mode_info['description'],
                type=button_type
        ):
            st.session_state.selected_mode = mode_key
            st.rerun()

# Show selected mode info
if st.session_state.get('selected_mode'):
    mode = st.session_state.selected_mode
    mode_info = QUERY_MODES[mode]

    st.markdown("---")

    # Mode description with validation info
    selected_mode_info = QUERY_MODES[mode]  # Get the actual selected mode info
    validation_priority = selected_mode_info.get("validation_priority",
                                                 "medium")  # Use selected_mode_info instead of mode_info

    if validation_priority == "high":
        st.info(f"ğŸ›¡ï¸ **{selected_mode_info['name']}** - æ­¤æ¨¡å¼åŒ…å«é«˜çº§ä¸“ä¸šéªŒè¯åŠŸèƒ½")
    elif validation_priority == "medium":
        st.info(f"ğŸ” **{selected_mode_info['name']}** - æ­¤æ¨¡å¼åŒ…å«åˆ†æéªŒè¯åŠŸèƒ½")
    else:
        st.info(f"ğŸ“ **{selected_mode_info['name']}** - {selected_mode_info['description']}")

    # Query input section
    st.subheader("ğŸ’­ è¾“å…¥æ‚¨çš„é—®é¢˜")

    # Show examples for the selected mode
    with st.expander(f"ğŸ’¡ {mode_info['name']} ç¤ºä¾‹"):
        for example in mode_info['examples']:
            if st.button(example, key=f"example_{example[:20]}", use_container_width=True):
                st.session_state.example_query = example

    # Handle pre-filled queries
    default_query = ""
    if hasattr(st.session_state, 'smart_query'):
        default_query = st.session_state.smart_query
        del st.session_state.smart_query
    elif hasattr(st.session_state, 'example_query'):
        default_query = st.session_state.example_query
        del st.session_state.example_query

    query = st.text_area(
        "è¯·è¾“å…¥æ‚¨çš„é—®é¢˜",
        value=default_query,
        placeholder=f"ä¾‹å¦‚ï¼š{mode_info['examples'][0]}",
        height=100
    )

    # UPDATED: Real-time validation feedback for high-priority modes
    if validation_priority == "high" and query.strip():
        render_real_time_validation_feedback(query)

    # Filters
    with st.expander("ğŸ”§ ç­›é€‰æ¡ä»¶ï¼ˆå¯é€‰ï¼‰"):
        filter_col1, filter_col2 = st.columns(2)

        with filter_col1:
            manufacturer = st.selectbox(
                "å“ç‰Œ",
                ["", "å®é©¬", "å¥”é©°", "å¥¥è¿ª", "ä¸°ç”°", "æœ¬ç”°", "ç‰¹æ–¯æ‹‰", "å¤§ä¼—"],
                key=f"manufacturer_{mode}"
            )

        with filter_col2:
            year = st.selectbox(
                "å¹´ä»½",
                [""] + [str(y) for y in range(2024, 2018, -1)],
                key=f"year_{mode}"
            )

    # Build filters
    filters = {}
    if manufacturer:
        filters["manufacturer"] = manufacturer
    if year:
        filters["year"] = int(year)

    # Submit button
    submit_text = f"ğŸš€ å¼€å§‹{mode_info['name']}"

    if st.button(
            submit_text,
            type="primary",
            disabled=not query.strip(),
            use_container_width=True
    ):
        if query.strip():
            with st.spinner(f"æ­£åœ¨è¿›è¡Œ{mode_info['name']}..."):
                job_id = submit_unified_query(query.strip(), mode, filters if filters else None)

                if job_id:
                    st.session_state.current_job_id = job_id
                    st.session_state.query_text = query.strip()
                    st.session_state.query_mode = mode
                    st.session_state.query_submitted_at = time.time()
                    st.success(f"âœ… {mode_info['name']}å·²æäº¤ï¼Œä»»åŠ¡ID: {job_id[:8]}...")
                    st.rerun()

else:
    st.info("ğŸ‘† è¯·é€‰æ‹©ä¸€ä¸ªæŸ¥è¯¢æ¨¡å¼å¼€å§‹åˆ†æ")

    # Quick start recommendations with validation info
    st.markdown("### ğŸš€ å¿«é€Ÿå¼€å§‹")
    rec_col1, rec_col2 = st.columns(2)

    with rec_col1:
        st.markdown("**æ–°ç”¨æˆ·æ¨èï¼š**")
        if st.button("ğŸ“Œ å¼€å§‹ä¿¡æ¯æ€»è§ˆ ğŸ›¡ï¸", type="primary", use_container_width=True,
                     help="åŒ…å«é«˜çº§ä¸“ä¸šéªŒè¯åŠŸèƒ½"):
            st.session_state.selected_mode = "facts"
            st.rerun()

    with rec_col2:
        st.markdown("**ä¸“ä¸šç”¨æˆ·æ¨èï¼š**")
        if st.button("ğŸ’¡ å¼€å§‹åŠŸèƒ½å»ºè®® âœ…", use_container_width=True,
                     help="åŒ…å«åŸºç¡€ä¸“ä¸šéªŒè¯åŠŸèƒ½"):
            st.session_state.selected_mode = "features"
            st.rerun()

# Enhanced results section
if hasattr(st.session_state, 'current_job_id') and st.session_state.current_job_id:
    job_id = st.session_state.current_job_id
    query_mode = getattr(st.session_state, 'query_mode', 'facts')
    mode_info = QUERY_MODES[query_mode]

    st.markdown("---")

    # Rate-limited result checking
    if 'last_result_check' not in st.session_state:
        st.session_state.last_result_check = 0

    current_time = time.time()
    if current_time - st.session_state.last_result_check > 3:
        result = get_query_result(job_id)
        st.session_state.last_query_result = result
        st.session_state.last_result_check = current_time
    else:
        result = st.session_state.get('last_query_result')

    if result:
        status = result.get("status", "")

        if status == "completed":
            st.success("âœ… åˆ†æå®Œæˆï¼")

            # UPDATED: Display results with unified validation system
            display_enhanced_results(result, query_mode)

            # Enhanced action buttons
            st.markdown("---")
            action_col1, action_col2, action_col3, action_col4 = st.columns(4)

            with action_col1:
                if st.button("ğŸ”„ æ–°çš„æŸ¥è¯¢", key="new_analysis"):
                    for key in ['current_job_id', 'query_text', 'last_query_result']:
                        if key in st.session_state:
                            del st.session_state[key]
                    st.rerun()

            with action_col2:
                if st.button("ğŸ”€ åˆ‡æ¢æ¨¡å¼", key="switch_mode"):
                    st.session_state.example_query = st.session_state.get('query_text', '')
                    for key in ['current_job_id', 'last_query_result']:
                        if key in st.session_state:
                            del st.session_state[key]
                    st.rerun()

            with action_col3:
                if st.button("ğŸ“‹ æŸ¥çœ‹è¯¦æƒ…", key="view_job_details"):
                    st.session_state.selected_job_id = job_id
                    st.switch_page("pages/åå°ä»»åŠ¡.py")

            with action_col4:
                if st.button("ğŸ›¡ï¸ éªŒè¯è¯´æ˜", key="validation_help"):
                    st.session_state.show_validation_help = True
                    st.rerun()

        elif status == "failed":
            st.error("âŒ åˆ†æå¤±è´¥")
            error_msg = result.get("answer", "æœªçŸ¥é”™è¯¯")
            st.error(f"é”™è¯¯ä¿¡æ¯: {error_msg}")

        else:
            st.info("â³ æ­£åœ¨åˆ†æä¸­...")
            progress_msg = result.get("answer", "æ­£åœ¨å¤„ç†æ‚¨çš„æŸ¥è¯¢...")
            st.info(progress_msg)

            if st.button("ğŸ”„ åˆ·æ–°çŠ¶æ€", key="refresh_status"):
                st.session_state.last_result_check = 0
                st.rerun()
    else:
        st.error("âŒ æ— æ³•è·å–åˆ†æçŠ¶æ€")

# UPDATED: Validation help modal using unified system
if st.session_state.get('show_validation_help', False):
    render_validation_help()

    if st.button("å…³é—­è¯´æ˜", key="close_help"):
        st.session_state.show_validation_help = False
        st.rerun()

# Navigation
st.markdown("---")
nav_cols = st.columns(4)

with nav_cols[0]:
    if st.button("ğŸ“¤ ä¸Šä¼ èµ„æ–™", use_container_width=True):
        st.switch_page("pages/æ•°æ®æ‘„å–.py")

with nav_cols[1]:
    if st.button("ğŸ“š æµè§ˆæ–‡æ¡£", use_container_width=True):
        st.switch_page("pages/æ–‡æ¡£æµè§ˆ.py")

with nav_cols[2]:
    if st.button("ğŸ“‹ æŸ¥çœ‹ä»»åŠ¡", use_container_width=True):
        st.switch_page("pages/åå°ä»»åŠ¡.py")

with nav_cols[3]:
    if st.button("ğŸ  è¿”å›ä¸»é¡µ", use_container_width=True):
        st.switch_page("src/ui/ä¸»é¡µ.py")

# Footer with validation info
st.markdown("---")
st.caption("ğŸ›¡ï¸ æ­¤æŸ¥è¯¢ç³»ç»Ÿé…å¤‡æ±½è½¦é¢†åŸŸä¸“ä¸šéªŒè¯åŠŸèƒ½ï¼Œå¸®åŠ©ç¡®ä¿ä¿¡æ¯å‡†ç¡®æ€§")
st.caption("âš ï¸ å¯¹äºé‡è¦å†³ç­–ï¼Œå»ºè®®ç»“åˆå¤šä¸ªæƒå¨æ¥æºè¿›è¡ŒéªŒè¯")