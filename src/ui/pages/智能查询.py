import streamlit as st
import time
import json
from typing import Dict, Any, Optional
from src.ui.api_client import api_request
from src.ui.session_init import initialize_session_state

initialize_session_state()

# Query mode configurations
QUERY_MODES = {
    "facts": {
        "icon": "ğŸ“Œ",
        "name": "è½¦è¾†è§„æ ¼æŸ¥è¯¢",
        "description": "éªŒè¯å…·ä½“çš„è½¦è¾†è§„æ ¼å‚æ•°",
        "use_case": "æŸ¥è¯¢ç¡®åˆ‡çš„æŠ€æœ¯è§„æ ¼ã€é…ç½®ä¿¡æ¯",
        "two_layer": True,
        "examples": [
            "2023å¹´å®é©¬X5çš„åå¤‡ç®±å®¹ç§¯æ˜¯å¤šå°‘ï¼Ÿ",
            "ç‰¹æ–¯æ‹‰Model 3çš„å……ç”µé€Ÿåº¦å‚æ•°",
            "å¥”é©°Eçº§ä½¿ç”¨ä»€ä¹ˆè½®èƒå‹å·ï¼Ÿ"
        ]
    },
    "features": {
        "icon": "ğŸ’¡",
        "name": "æ–°åŠŸèƒ½å»ºè®®",
        "description": "è¯„ä¼°æ˜¯å¦åº”è¯¥æ·»åŠ æŸé¡¹åŠŸèƒ½",
        "use_case": "äº§å“å†³ç­–ï¼ŒåŠŸèƒ½è§„åˆ’",
        "two_layer": True,
        "examples": [
            "æ˜¯å¦åº”è¯¥ä¸ºç”µåŠ¨è½¦å¢åŠ æ°›å›´ç¯åŠŸèƒ½ï¼Ÿ",
            "å¢åŠ æ¨¡æ‹Ÿå¼•æ“å£°éŸ³å¯¹ç”¨æˆ·ä½“éªŒçš„å½±å“",
            "ARæŠ¬å¤´æ˜¾ç¤ºå™¨å€¼å¾—æŠ•èµ„å—ï¼Ÿ"
        ]
    },
    "tradeoffs": {
        "icon": "ğŸ§¾",
        "name": "æƒè¡¡åˆ©å¼Šåˆ†æ",
        "description": "åˆ†æè®¾è®¡é€‰æ‹©çš„ä¼˜ç¼ºç‚¹",
        "use_case": "è®¾è®¡å†³ç­–ï¼ŒæŠ€æœ¯é€‰å‹",
        "two_layer": True,
        "examples": [
            "ä½¿ç”¨æ¨¡æ‹Ÿå£°éŸ³ vs è‡ªç„¶é™éŸ³çš„åˆ©å¼Š",
            "ç§»é™¤ç‰©ç†æŒ‰é”®çš„ä¼˜ç¼ºç‚¹åˆ†æ",
            "å¤§å±å¹• vs ä¼ ç»Ÿä»ªè¡¨ç›˜çš„å¯¹æ¯”"
        ]
    },
    "scenarios": {
        "icon": "ğŸ§©",
        "name": "ç”¨æˆ·åœºæ™¯åˆ†æ",
        "description": "è¯„ä¼°åŠŸèƒ½åœ¨å®é™…ä½¿ç”¨åœºæ™¯ä¸­çš„è¡¨ç°",
        "use_case": "ç”¨æˆ·ä½“éªŒè®¾è®¡ï¼Œäº§å“è§„åˆ’",
        "two_layer": True,
        "examples": [
            "é•¿é€”æ—…è¡Œæ—¶è¿™ä¸ªåŠŸèƒ½å¦‚ä½•è¡¨ç°ï¼Ÿ",
            "å®¶åº­ç”¨æˆ·åœ¨æ—¥å¸¸é€šå‹¤ä¸­çš„ä½“éªŒå¦‚ä½•ï¼Ÿ",
            "å¯’å†·æ°”å€™ä¸‹çš„æ€§èƒ½è¡¨ç°åˆ†æ"
        ]
    },
    "debate": {
        "icon": "ğŸ—£ï¸",
        "name": "å¤šè§’è‰²è®¨è®º",
        "description": "æ¨¡æ‹Ÿä¸åŒè§’è‰²çš„è§‚ç‚¹å’Œè®¨è®º",
        "use_case": "å†³ç­–æ”¯æŒï¼Œå…¨é¢è¯„ä¼°",
        "two_layer": False,
        "examples": [
            "äº§å“ç»ç†ã€å·¥ç¨‹å¸ˆå’Œç”¨æˆ·ä»£è¡¨å¦‚ä½•çœ‹å¾…è‡ªåŠ¨é©¾é©¶åŠŸèƒ½ï¼Ÿ",
            "ä¸åŒå›¢é˜Ÿå¯¹ç”µæ± æŠ€æœ¯è·¯çº¿çš„è§‚ç‚¹",
            "å…³äºè½¦å†…ç©ºé—´è®¾è®¡çš„å¤šæ–¹è®¨è®º"
        ]
    },
    "quotes": {
        "icon": "ğŸ”",
        "name": "åŸå§‹ç”¨æˆ·è¯„è®º",
        "description": "æå–ç›¸å…³çš„ç”¨æˆ·è¯„è®ºå’Œåé¦ˆ",
        "use_case": "å¸‚åœºç ”ç©¶ï¼Œç”¨æˆ·æ´å¯Ÿ",
        "two_layer": False,
        "examples": [
            "ç”¨æˆ·å¯¹ç»­èˆªé‡Œç¨‹çš„çœŸå®è¯„ä»·",
            "å…³äºå†…é¥°è´¨é‡çš„ç”¨æˆ·åé¦ˆ",
            "å……ç”µä½“éªŒçš„ç”¨æˆ·è¯„è®ºæ‘˜å½•"
        ]
    }
}

# Prompt templates for each mode
PROMPT_TEMPLATES = {
    "facts": """ä½ æ˜¯ä¸“ä¸šçš„æ±½è½¦æŠ€æœ¯è§„æ ¼éªŒè¯ä¸“å®¶ã€‚è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼å›ç­”ï¼š

ã€å®è¯ç­”æ¡ˆã€‘
åŸºäºæä¾›çš„æ–‡æ¡£å†…å®¹ï¼Œå›ç­”ç”¨æˆ·çš„å…·ä½“é—®é¢˜ã€‚å¦‚æœæ–‡æ¡£ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œå¿…é¡»æ˜ç¡®è¯´æ˜"æ ¹æ®æä¾›çš„æ–‡æ¡£ï¼ŒæœªæåŠç›¸å…³ä¿¡æ¯"ã€‚

ã€æ¨ç†è¡¥å……ã€‘
å¦‚æœæœ‰éœ€è¦ï¼Œå¯ä»¥åŸºäºæ±½è½¦è¡Œä¸šå¸¸è¯†è¿›è¡Œåˆç†æ¨æµ‹ï¼Œä½†å¿…é¡»æ¸…æ¥šæ ‡æ³¨è¿™æ˜¯æ¨ç†è€Œéæ–‡æ¡£äº‹å®ã€‚

ç”¨æˆ·æŸ¥è¯¢ï¼š{query}
æ–‡æ¡£å†…å®¹ï¼š{context}

è¯·ç¡®ä¿å›ç­”ç²¾ç¡®ã€å¯éªŒè¯ï¼Œå¹¶æ˜ç¡®åŒºåˆ†äº‹å®å’Œæ¨ç†ã€‚""",

    "features": """ä½ æ˜¯æ±½è½¦äº§å“ç­–ç•¥ä¸“å®¶ã€‚è¯·æŒ‰ç…§ä»¥ä¸‹æ ¼å¼åˆ†ææ˜¯å¦åº”è¯¥æ·»åŠ æŸé¡¹åŠŸèƒ½ï¼š

ã€å®è¯åˆ†æã€‘
åŸºäºæä¾›çš„æ–‡æ¡£ä¸­å…³äºç±»ä¼¼åŠŸèƒ½æˆ–ç›¸å…³æŠ€æœ¯çš„ä¿¡æ¯è¿›è¡Œåˆ†æã€‚

ã€ç­–ç•¥æ¨ç†ã€‘
åŸºäºäº§å“æ€ç»´å’Œç”¨æˆ·éœ€æ±‚ï¼Œåˆ†æè¿™ä¸ªåŠŸèƒ½çš„æ½œåœ¨ä»·å€¼ï¼š
- ç”¨æˆ·å—ç›Šåˆ†æ
- æŠ€æœ¯å¯è¡Œæ€§
- å¸‚åœºç«äº‰ä¼˜åŠ¿
- æˆæœ¬æ•ˆç›Šè¯„ä¼°

ç”¨æˆ·è¯¢é—®åŠŸèƒ½ï¼š{query}
å‚è€ƒæ–‡æ¡£ï¼š{context}

è¯·æä¾›å¹³è¡¡çš„è¯„ä¼°æ„è§ã€‚""",

    "tradeoffs": """ä½ æ˜¯æ±½è½¦è®¾è®¡å†³ç­–åˆ†æå¸ˆã€‚è¯·æŒ‰ç…§ä»¥ä¸‹æ ¼å¼åˆ†æè®¾è®¡é€‰æ‹©çš„åˆ©å¼Šï¼š

ã€æ–‡æ¡£æ”¯æ’‘ã€‘
åŸºäºæä¾›æ–‡æ¡£ä¸­çš„ç›¸å…³ä¿¡æ¯å’Œæ•°æ®ã€‚

ã€åˆ©å¼Šåˆ†æã€‘
**ä¼˜ç‚¹ï¼š**
- [åŸºäºæ–‡æ¡£çš„ä¼˜ç‚¹]
- [æ¨ç†å¾—å‡ºçš„ä¼˜ç‚¹]

**ç¼ºç‚¹ï¼š**
- [åŸºäºæ–‡æ¡£çš„ç¼ºç‚¹] 
- [æ¨ç†å¾—å‡ºçš„ç¼ºç‚¹]

**æ€»ç»“å»ºè®®ï¼š**
ç»¼åˆè¯„ä¼°å’Œå»ºè®®

è®¾è®¡å†³ç­–ï¼š{query}
å‚è€ƒèµ„æ–™ï¼š{context}

è¯·ç¡®ä¿åˆ†æå®¢è§‚å…¨é¢ã€‚""",

    "scenarios": """ä½ æ˜¯ç”¨æˆ·ä½“éªŒåˆ†æä¸“å®¶ã€‚è¯·æŒ‰ç…§ä»¥ä¸‹æ ¼å¼åˆ†æåŠŸèƒ½åœ¨ä¸åŒåœºæ™¯ä¸‹çš„è¡¨ç°ï¼š

ã€æ–‡æ¡£åœºæ™¯ã€‘
æå–æ–‡æ¡£ä¸­æåˆ°çš„ä½¿ç”¨åœºæ™¯å’Œç”¨æˆ·åé¦ˆã€‚

ã€åœºæ™¯æ¨ç†ã€‘
åŸºäºäº§å“æ€ç»´å’Œç”¨æˆ·åŒç†å¿ƒï¼Œåˆ†æåœ¨ä»¥ä¸‹åœºæ™¯ä¸­çš„è¡¨ç°ï¼š
- è°ä¼šå—ç›Šï¼ˆç›®æ ‡ç”¨æˆ·ç¾¤ï¼‰
- ä»€ä¹ˆæ—¶å€™æœ‰ç”¨ï¼ˆä½¿ç”¨æ—¶æœºï¼‰
- ä»€ä¹ˆæ¡ä»¶ä¸‹æ•ˆæœæœ€å¥½ï¼ˆæœ€ä½³ä½¿ç”¨æ¡ä»¶ï¼‰
- å¯èƒ½çš„é—®é¢˜å’Œé™åˆ¶

åˆ†æä¸»é¢˜ï¼š{query}
å‚è€ƒä¿¡æ¯ï¼š{context}

è¯·æä¾›å…·ä½“ã€å®ç”¨çš„åœºæ™¯åˆ†æã€‚""",

    "debate": """ä½ æ˜¯æ±½è½¦è¡Œä¸šåœ†æ¡Œè®¨è®ºä¸»æŒäººã€‚è¯·æ¨¡æ‹Ÿä»¥ä¸‹è§’è‰²çš„è®¨è®ºï¼š

**äº§å“ç»ç†è§‚ç‚¹ï¼š**
ä»å•†ä¸šä»·å€¼å’Œç”¨æˆ·éœ€æ±‚è§’åº¦åˆ†æ

**å·¥ç¨‹å¸ˆè§‚ç‚¹ï¼š** 
ä»æŠ€æœ¯å®ç°å’Œæˆæœ¬è§’åº¦åˆ†æ

**ç”¨æˆ·ä»£è¡¨è§‚ç‚¹ï¼š**
ä»å®é™…ä½¿ç”¨ä½“éªŒå’Œéœ€æ±‚è§’åº¦åˆ†æ

è®¨è®ºè¯é¢˜ï¼š{query}
å‚è€ƒä¿¡æ¯ï¼š{context}

è¯·è®©æ¯ä¸ªè§’è‰²æå‡ºä¸åŒçš„è§‚ç‚¹ï¼Œæœ€åæ€»ç»“å…±è¯†å’Œåˆ†æ­§ç‚¹ã€‚""",

    "quotes": """ä½ æ˜¯æ±½è½¦å¸‚åœºç ”ç©¶åˆ†æå¸ˆã€‚è¯·ä»æä¾›çš„æ–‡æ¡£ä¸­æå–ç”¨æˆ·çš„åŸå§‹è¯„è®ºå’Œåé¦ˆï¼š

è¯·æŒ‰ä»¥ä¸‹æ ¼å¼æä¾›ç”¨æˆ·è¯„è®ºï¼š

ã€æ¥æº1ã€‘ï¼š"ç”¨æˆ·åŸå§‹è¯„è®ºå†…å®¹..."
ã€æ¥æº2ã€‘ï¼š"ç”¨æˆ·åŸå§‹è¯„è®ºå†…å®¹..."
ã€æ¥æº3ã€‘ï¼š"ç”¨æˆ·åŸå§‹è¯„è®ºå†…å®¹..."

æŸ¥è¯¢ä¸»é¢˜ï¼š{query}
æ–‡æ¡£æ¥æºï¼š{context}

åªæå–çœŸå®çš„ç”¨æˆ·è¯„è®ºï¼Œä¸è¦ç¼–é€ å†…å®¹ã€‚å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç›¸å…³çš„ç”¨æˆ·è¯„è®ºï¼Œè¯·æ˜ç¡®è¯´æ˜ã€‚"""
}


def submit_enhanced_query(query_text: str, mode: str, filters: Optional[Dict] = None) -> Optional[str]:
    """Submit enhanced query with specific prompt template"""
    try:
        # Get the prompt template for the selected mode
        template = PROMPT_TEMPLATES.get(mode, PROMPT_TEMPLATES["facts"])

        # Enhanced query data
        enhanced_data = {
            "query": query_text,
            "metadata_filter": filters,
            "top_k": 8,  # Get more documents for better analysis
            "query_mode": mode,
            "prompt_template": template
        }

        result = api_request(
            endpoint="/query/",
            method="POST",
            data=enhanced_data
        )

        if result and "job_id" in result:
            return result["job_id"]
        else:
            st.error("æŸ¥è¯¢æäº¤å¤±è´¥ï¼šæœåŠ¡å™¨æœªè¿”å›æœ‰æ•ˆå“åº”")
            return None

    except Exception as e:
        st.error(f"æŸ¥è¯¢æäº¤æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
        return None


def get_query_result(job_id: str) -> Optional[Dict]:
    """Get query results"""
    try:
        return api_request(f"/query/results/{job_id}", method="GET")
    except Exception as e:
        st.error(f"è·å–æŸ¥è¯¢ç»“æœæ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
        return None


def display_two_layer_result(result: Dict[str, Any], mode: str):
    """Display results with two-layer structure"""
    answer = result.get("answer", "")

    if not answer:
        st.warning("æœªè·å¾—æŸ¥è¯¢ç»“æœ")
        return

    # Parse two-layer structure based on mode
    if mode == "facts":
        # Look for ã€å®è¯ç­”æ¡ˆã€‘ and ã€æ¨ç†è¡¥å……ã€‘
        sections = parse_structured_answer(answer, ["ã€å®è¯ç­”æ¡ˆã€‘", "ã€æ¨ç†è¡¥å……ã€‘"])

        if sections.get("ã€å®è¯ç­”æ¡ˆã€‘"):
            st.subheader("ğŸ“‹ å®è¯ç­”æ¡ˆ")
            st.info(sections["ã€å®è¯ç­”æ¡ˆã€‘"])

        if sections.get("ã€æ¨ç†è¡¥å……ã€‘"):
            st.subheader("ğŸ§  æ¨ç†è¡¥å……")
            st.warning(sections["ã€æ¨ç†è¡¥å……ã€‘"])

    elif mode == "features":
        sections = parse_structured_answer(answer, ["ã€å®è¯åˆ†æã€‘", "ã€ç­–ç•¥æ¨ç†ã€‘"])

        if sections.get("ã€å®è¯åˆ†æã€‘"):
            st.subheader("ğŸ“Š å®è¯åˆ†æ")
            st.info(sections["ã€å®è¯åˆ†æã€‘"])

        if sections.get("ã€ç­–ç•¥æ¨ç†ã€‘"):
            st.subheader("ğŸ’¡ ç­–ç•¥æ¨ç†")
            st.success(sections["ã€ç­–ç•¥æ¨ç†ã€‘"])

    elif mode == "tradeoffs":
        sections = parse_structured_answer(answer, ["ã€æ–‡æ¡£æ”¯æ’‘ã€‘", "ã€åˆ©å¼Šåˆ†æã€‘"])

        if sections.get("ã€æ–‡æ¡£æ”¯æ’‘ã€‘"):
            st.subheader("ğŸ“‹ æ–‡æ¡£æ”¯æ’‘")
            st.info(sections["ã€æ–‡æ¡£æ”¯æ’‘ã€‘"])

        if sections.get("ã€åˆ©å¼Šåˆ†æã€‘"):
            st.subheader("âš–ï¸ åˆ©å¼Šåˆ†æ")
            st.warning(sections["ã€åˆ©å¼Šåˆ†æã€‘"])

    elif mode == "scenarios":
        sections = parse_structured_answer(answer, ["ã€æ–‡æ¡£åœºæ™¯ã€‘", "ã€åœºæ™¯æ¨ç†ã€‘"])

        if sections.get("ã€æ–‡æ¡£åœºæ™¯ã€‘"):
            st.subheader("ğŸ“– æ–‡æ¡£åœºæ™¯")
            st.info(sections["ã€æ–‡æ¡£åœºæ™¯ã€‘"])

        if sections.get("ã€åœºæ™¯æ¨ç†ã€‘"):
            st.subheader("ğŸ¯ åœºæ™¯æ¨ç†")
            st.success(sections["ã€åœºæ™¯æ¨ç†ã€‘"])
    else:
        # Fallback: show full answer
        st.markdown(answer)


def parse_structured_answer(answer: str, section_headers: list) -> Dict[str, str]:
    """Parse structured answer into sections"""
    sections = {}
    current_section = None
    current_content = []

    lines = answer.split('\n')

    for line in lines:
        line = line.strip()

        # Check if this line is a section header
        found_header = None
        for header in section_headers:
            if header in line:
                found_header = header
                break

        if found_header:
            # Save previous section if exists
            if current_section and current_content:
                sections[current_section] = '\n'.join(current_content).strip()

            # Start new section
            current_section = found_header
            current_content = []
        elif current_section:
            # Add content to current section
            if line:  # Only add non-empty lines
                current_content.append(line)

    # Save the last section
    if current_section and current_content:
        sections[current_section] = '\n'.join(current_content).strip()

    return sections


def display_debate_result(answer: str):
    """Display debate-style results with multiple perspectives"""
    st.subheader("ğŸ—£ï¸ å¤šè§’è‰²è®¨è®º")

    # Look for role-based sections
    roles = ["äº§å“ç»ç†è§‚ç‚¹", "å·¥ç¨‹å¸ˆè§‚ç‚¹", "ç”¨æˆ·ä»£è¡¨è§‚ç‚¹"]
    sections = {}

    current_role = None
    current_content = []

    lines = answer.split('\n')

    for line in lines:
        line = line.strip()

        # Check for role headers
        found_role = None
        for role in roles:
            if role in line or f"**{role}" in line:
                found_role = role
                break

        if found_role:
            # Save previous role content
            if current_role and current_content:
                sections[current_role] = '\n'.join(current_content).strip()

            current_role = found_role
            current_content = []
        elif current_role and line:
            current_content.append(line)

    # Save last role
    if current_role and current_content:
        sections[current_role] = '\n'.join(current_content).strip()

    # Display each perspective
    role_icons = {
        "äº§å“ç»ç†è§‚ç‚¹": "ğŸ‘”",
        "å·¥ç¨‹å¸ˆè§‚ç‚¹": "ğŸ”§",
        "ç”¨æˆ·ä»£è¡¨è§‚ç‚¹": "ğŸ‘¥"
    }

    if sections:
        for role, content in sections.items():
            if content:
                icon = role_icons.get(role, "ğŸ’¬")
                st.markdown(f"### {icon} {role}")
                st.markdown(content)
                st.markdown("---")
    else:
        # Fallback: display full answer
        st.markdown(answer)


def display_quotes_result(answer: str):
    """Display user quotes in a structured format"""
    st.subheader("ğŸ’¬ ç”¨æˆ·è¯„è®ºæ‘˜å½•")

    # Look for quote patterns like ã€æ¥æº1ã€‘ï¼š"..."
    import re
    quote_pattern = r'ã€æ¥æº\d+ã€‘[ï¼š:]"([^"]+)"'
    quotes = re.findall(quote_pattern, answer)

    if quotes:
        for i, quote in enumerate(quotes, 1):
            with st.container():
                st.markdown(f"**æ¥æº {i}:**")
                st.quote(quote)
                st.markdown("")
    else:
        # Fallback: display full answer
        st.markdown(answer)


# Main interface
st.title("ğŸ” æ™ºèƒ½æ±½è½¦æŸ¥è¯¢")
st.markdown("å¤šè§’åº¦åˆ†ææ¨¡å¼ï¼Œé€‚åˆä¸åŒçš„æŸ¥è¯¢éœ€æ±‚")

# Mode selection
st.subheader("ğŸ“‹ é€‰æ‹©æŸ¥è¯¢æ¨¡å¼")

# Display modes in a grid
mode_cols = st.columns(3)
selected_mode = None

for i, (mode_key, mode_info) in enumerate(QUERY_MODES.items()):
    col = mode_cols[i % 3]

    with col:
        if st.button(
                f"{mode_info['icon']} {mode_info['name']}",
                key=f"mode_{mode_key}",
                use_container_width=True,
                help=mode_info['description']
        ):
            selected_mode = mode_key

# Show selected mode info
if selected_mode:
    st.session_state.selected_mode = selected_mode

if 'selected_mode' in st.session_state:
    mode = st.session_state.selected_mode
    mode_info = QUERY_MODES[mode]

    st.success(f"å·²é€‰æ‹©ï¼š{mode_info['icon']} {mode_info['name']}")
    st.markdown(f"**é€‚ç”¨åœºæ™¯ï¼š** {mode_info['use_case']}")

    # Query input
    st.subheader("ğŸ’­ è¾“å…¥æ‚¨çš„é—®é¢˜")

    # Show examples for the selected mode
    with st.expander(f"ğŸ’¡ {mode_info['name']} ç¤ºä¾‹"):
        for example in mode_info['examples']:
            if st.button(example, key=f"example_{example[:20]}", use_container_width=True):
                st.session_state.example_query = example

    # Use example query if selected
    default_query = st.session_state.get('example_query', '')
    if default_query:
        del st.session_state.example_query

    query = st.text_area(
        "è¯·è¾“å…¥æ‚¨çš„é—®é¢˜",
        value=default_query,
        placeholder=f"ä¾‹å¦‚ï¼š{mode_info['examples'][0]}",
        height=100,
        help=f"å½“å‰æ¨¡å¼ï¼š{mode_info['description']}"
    )

    # Filters (simplified for UX)
    with st.expander("ğŸ”§ ç­›é€‰æ¡ä»¶ï¼ˆå¯é€‰ï¼‰"):
        filter_col1, filter_col2 = st.columns(2)

        with filter_col1:
            manufacturer = st.selectbox(
                "å“ç‰Œ",
                ["", "å®é©¬", "å¥”é©°", "å¥¥è¿ª", "ä¸°ç”°", "æœ¬ç”°", "ç‰¹æ–¯æ‹‰", "å¤§ä¼—"],
                key=f"manufacturer_{mode}"
            )

        with filter_col2:
            year = st.selectbox(
                "å¹´ä»½",
                [""] + [str(y) for y in range(2024, 2018, -1)],
                key=f"year_{mode}"
            )

    # Build filters
    filters = {}
    if manufacturer:
        filters["manufacturer"] = manufacturer
    if year:
        filters["year"] = int(year)

    # Submit button
    if st.button(
            f"ğŸš€ å¼€å§‹{mode_info['name']}",
            type="primary",
            disabled=not query.strip(),
            use_container_width=True
    ):
        if query.strip():
            with st.spinner(f"æ­£åœ¨è¿›è¡Œ{mode_info['name']}..."):
                job_id = submit_enhanced_query(query.strip(), mode, filters if filters else None)

                if job_id:
                    st.session_state.current_job_id = job_id
                    st.session_state.query_text = query.strip()
                    st.session_state.query_mode = mode
                    st.session_state.query_submitted_at = time.time()
                    st.success(f"âœ… {mode_info['name']}å·²æäº¤ï¼Œä»»åŠ¡ID: {job_id[:8]}...")
                    st.rerun()

# Results section
if hasattr(st.session_state, 'current_job_id') and st.session_state.current_job_id:
    job_id = st.session_state.current_job_id
    query_mode = getattr(st.session_state, 'query_mode', 'facts')
    mode_info = QUERY_MODES[query_mode]

    st.markdown("---")
    st.subheader(f"ğŸ“‹ {mode_info['name']} ç»“æœ")

    # Get results with minimal API calls
    if 'last_result_check' not in st.session_state:
        st.session_state.last_result_check = 0

    current_time = time.time()
    if current_time - st.session_state.last_result_check > 3:  # Check every 3 seconds
        result = get_query_result(job_id)
        st.session_state.last_query_result = result
        st.session_state.last_result_check = current_time
    else:
        result = st.session_state.get('last_query_result')

    if result:
        status = result.get("status", "")

        if status == "completed":
            st.success("âœ… åˆ†æå®Œæˆï¼")

            # Display results based on mode
            if mode_info['two_layer']:
                display_two_layer_result(result, query_mode)
            elif query_mode == "debate":
                display_debate_result(result.get("answer", ""))
            elif query_mode == "quotes":
                display_quotes_result(result.get("answer", ""))
            else:
                st.markdown(result.get("answer", ""))

            # Show sources
            documents = result.get("documents", [])
            if documents:
                with st.expander(f"ğŸ“š å‚è€ƒæ¥æº ({len(documents)} ä¸ª)"):
                    for i, doc in enumerate(documents[:5]):
                        st.markdown(f"**æ¥æº {i + 1}:** {doc.get('metadata', {}).get('title', 'æ–‡æ¡£')}")
                        if doc.get("content"):
                            st.caption(doc['content'][:200] + "...")
                        st.markdown("---")

            # Actions for completed queries
            action_col1, action_col2 = st.columns(2)
            with action_col1:
                if st.button("ğŸ”„ æ–°çš„åˆ†æ", key="new_analysis"):
                    # Clear session state
                    for key in ['current_job_id', 'query_text', 'last_query_result', 'selected_mode']:
                        if key in st.session_state:
                            del st.session_state[key]
                    st.rerun()

            with action_col2:
                if st.button("ğŸ“‹ æŸ¥çœ‹è¯¦æƒ…", key="view_job_details"):
                    st.session_state.selected_job_id = job_id
                    st.switch_page("pages/åå°ä»»åŠ¡.py")

        elif status == "failed":
            st.error("âŒ åˆ†æå¤±è´¥")
            error_msg = result.get("answer", "æœªçŸ¥é”™è¯¯")
            st.error(f"é”™è¯¯ä¿¡æ¯: {error_msg}")

        else:
            # Still processing
            st.info("â³ æ­£åœ¨åˆ†æä¸­...")
            progress_msg = result.get("answer", "æ­£åœ¨å¤„ç†æ‚¨çš„æŸ¥è¯¢...")
            st.info(progress_msg)

            # Manual refresh option
            if st.button("ğŸ”„ åˆ·æ–°çŠ¶æ€", key="refresh_status"):
                st.session_state.last_result_check = 0
                st.rerun()
    else:
        st.error("âŒ æ— æ³•è·å–åˆ†æçŠ¶æ€")

else:
    # Initial instructions
    st.info("ğŸ‘† è¯·é€‰æ‹©ä¸€ä¸ªæŸ¥è¯¢æ¨¡å¼å¼€å§‹åˆ†æ")

    # Mode comparison table
    st.subheader("ğŸ“Š æ¨¡å¼å¯¹æ¯”")

    comparison_data = []
    for mode_key, mode_info in QUERY_MODES.items():
        comparison_data.append({
            "æ¨¡å¼": f"{mode_info['icon']} {mode_info['name']}",
            "æè¿°": mode_info['description'],
            "é€‚ç”¨åœºæ™¯": mode_info['use_case'],
            "è¾“å‡ºç»“æ„": "åŒå±‚ç»“æ„" if mode_info['two_layer'] else "å•å±‚è¾“å‡º"
        })

    # Display as table
    import pandas as pd

    df = pd.DataFrame(comparison_data)
    st.dataframe(df, use_container_width=True, hide_index=True)

# Navigation
st.markdown("---")
nav_cols = st.columns(4)

with nav_cols[0]:
    if st.button("ğŸ” åŸºç¡€æŸ¥è¯¢", use_container_width=True):
        st.switch_page("pages/æŸ¥è¯¢.py")

with nav_cols[1]:
    if st.button("ğŸ“¤ ä¸Šä¼ èµ„æ–™", use_container_width=True):
        st.switch_page("pages/æ•°æ®æ‘„å–.py")

with nav_cols[2]:
    if st.button("ğŸ“‹ æŸ¥çœ‹ä»»åŠ¡", use_container_width=True):
        st.switch_page("pages/åå°ä»»åŠ¡.py")

with nav_cols[3]:
    if st.button("ğŸ  è¿”å›ä¸»é¡µ", use_container_width=True):
        st.switch_page("src/ui/ä¸»é¡µ.py")

st.caption("æ™ºèƒ½æŸ¥è¯¢ - å¤šè§’åº¦æ·±åº¦åˆ†æï¼Œé€‚åˆä¸“ä¸šç”¨æˆ·çš„ä¸åŒéœ€æ±‚")