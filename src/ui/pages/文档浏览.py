"""
Enhanced æ–‡æ¡£æµè§ˆ.py with metadata display integration
"""

import streamlit as st
import time
from typing import Dict, Any, List
from src.ui.api_client import api_request
from src.ui.session_init import initialize_session_state

# Import enhanced metadata display components
from src.ui.components.metadata_display import (
    render_metadata_summary_card,
    render_embedded_metadata_display,
    EmbeddedMetadataExtractor
)

initialize_session_state()

st.title("ğŸ“š æ–‡æ¡£æµè§ˆ")
st.markdown("æµè§ˆå‘é‡æ•°æ®åº“ä¸­çš„æ‰€æœ‰æ–‡æ¡£ï¼ŒåŒ…å«è¯¦ç»†å…ƒæ•°æ®åˆ†æ")


def get_vector_store_documents(limit: int = 100, source_filter: str = None) -> List[Dict]:
    """Get documents from vector store with optional filtering"""
    try:
        # Use the debug endpoint to get documents
        endpoint = "/query/debug-retrieval"

        # If we have a source filter, use it as a query to find matching docs
        if source_filter and source_filter != "å…¨éƒ¨":
            query = source_filter
        else:
            query = "document"  # Generic query to get all docs

        result = api_request(
            endpoint=endpoint,
            method="POST",
            data={"query": query, "limit": str(limit)}
        )

        if result and "documents" in result:
            docs = result["documents"]

            # Apply source filtering if specified
            if source_filter and source_filter != "å…¨éƒ¨":
                filtered_docs = []
                for doc in docs:
                    doc_source = doc.get("metadata", {}).get("source", "")
                    if source_filter.lower() in doc_source.lower():
                        filtered_docs.append(doc)
                return filtered_docs[:limit]

            return docs[:limit]

        return []
    except Exception as e:
        st.error(f"è·å–æ–‡æ¡£æ—¶å‡ºé”™: {str(e)}")
        return []


def format_document_source(metadata: Dict) -> str:
    """Format document source for display"""
    source = metadata.get("source", "unknown")
    source_icons = {
        "youtube": "ğŸ¬ YouTube",
        "bilibili": "ğŸ“º Bilibili",
        "pdf": "ğŸ“„ PDF",
        "manual": "âœï¸ æ‰‹åŠ¨è¾“å…¥",
        "video": "ğŸ¥ è§†é¢‘"
    }
    return source_icons.get(source, f"ğŸ“„ {source}")


def display_enhanced_document_card(doc: Dict, index: int):
    """Display a document card with enhanced metadata display"""
    metadata = doc.get("metadata", {})
    content = doc.get("content", "")

    # Create expandable card
    with st.container():
        # Header with basic info
        col1, col2, col3 = st.columns([2, 1, 1])

        with col1:
            title = metadata.get("title", f"æ–‡æ¡£ {index + 1}")
            st.markdown(f"**{format_document_source(metadata)}**")
            st.markdown(f"ğŸ“„ {title}")

        with col2:
            if metadata.get("author"):
                st.caption(f"ğŸ‘¤ {metadata['author']}")
            if metadata.get("language"):
                st.caption(f"ğŸŒ {metadata['language']}")

        with col3:
            # Document stats
            word_count = len(content.split()) if content else 0
            st.caption(f"ğŸ“Š {word_count} è¯")

            chunk_info = ""
            if metadata.get("chunk_index") is not None and metadata.get("total_chunks"):
                chunk_info = f"ç‰‡æ®µ {metadata['chunk_index'] + 1}/{metadata['total_chunks']}"
            elif metadata.get("chunk_index") is not None:
                chunk_info = f"ç‰‡æ®µ {metadata['chunk_index'] + 1}"

            if chunk_info:
                st.caption(f"ğŸ”¢ {chunk_info}")

        # Enhanced metadata summary card
        st.markdown("**ğŸ·ï¸ å…ƒæ•°æ®æ‘˜è¦:**")
        # FIXED: Add unique_id to prevent key conflicts
        unique_id = f"doc_browser_{index}"
        render_metadata_summary_card(doc, compact=True, unique_id=unique_id)

        # Control buttons
        expand_key = f"expand_doc_{index}"
        metadata_key = f"show_metadata_{index}"

        col_btn1, col_btn2, col_btn3 = st.columns(3)

        with col_btn1:
            if st.button(f"ğŸ“‹ åŸºæœ¬ä¿¡æ¯", key=f"expand_btn_{index}"):
                current_state = st.session_state.get(expand_key, False)
                st.session_state[expand_key] = not current_state
                # Close metadata view if opening basic info
                if not current_state:
                    st.session_state[metadata_key] = False
                st.rerun()

        with col_btn2:
            if st.button(f"ğŸ·ï¸ è¯¦ç»†å…ƒæ•°æ®", key=f"metadata_btn_{index}"):
                current_state = st.session_state.get(metadata_key, False)
                st.session_state[metadata_key] = not current_state
                # Close basic info if opening metadata
                if not current_state:
                    st.session_state[expand_key] = False
                st.rerun()

        with col_btn3:
            # Quick metadata quality indicator
            extractor = EmbeddedMetadataExtractor()
            embedded_metadata, _ = extractor.extract_embedded_metadata(content)
            metadata_injected = metadata.get('metadata_injected', False)

            if metadata_injected and embedded_metadata:
                st.button("âœ… å…ƒæ•°æ®ä¼˜ç§€", key=f"quality_btn_{index}", disabled=True)
            elif embedded_metadata:
                st.button("âš ï¸ å…ƒæ•°æ®è‰¯å¥½", key=f"quality_btn_{index}", disabled=True)
            else:
                st.button("âŒ å…ƒæ•°æ®ç¼ºå¤±", key=f"quality_btn_{index}", disabled=True)

        # Show basic details if expanded
        if st.session_state.get(expand_key, False):
            st.markdown("---")
            st.markdown("**ğŸ“‹ åŸºæœ¬ä¿¡æ¯:**")

            # Basic info
            meta_col1, meta_col2 = st.columns(2)
            with meta_col1:
                st.write(f"**æ¥æºç±»å‹:** {format_document_source(metadata)}")
                if metadata.get("source_id"):
                    st.write(f"**æ¥æºID:** {metadata['source_id']}")
                if metadata.get("url"):
                    st.write(f"**é“¾æ¥:** [æŸ¥çœ‹åŸæ–‡]({metadata['url']})")
                if metadata.get("published_date"):
                    st.write(f"**å‘å¸ƒæ—¥æœŸ:** {metadata['published_date']}")

            with meta_col2:
                if metadata.get("manufacturer"):
                    st.write(f"**åˆ¶é€ å•†:** {metadata['manufacturer']}")
                if metadata.get("model"):
                    st.write(f"**è½¦å‹:** {metadata['model']}")
                if metadata.get("year"):
                    st.write(f"**å¹´ä»½:** {metadata['year']}")
                if metadata.get("category"):
                    st.write(f"**ç±»åˆ«:** {metadata['category']}")

            # Technical metadata
            if any(metadata.get(key) for key in ["duration", "view_count", "transcription_method"]):
                st.markdown("**ğŸ”§ æŠ€æœ¯ä¿¡æ¯:**")
                tech_col1, tech_col2 = st.columns(2)
                with tech_col1:
                    if metadata.get("duration"):
                        duration_mins = metadata['duration'] // 60
                        duration_secs = metadata['duration'] % 60
                        st.write(f"**è§†é¢‘æ—¶é•¿:** {duration_mins}åˆ†{duration_secs}ç§’")
                    if metadata.get("transcription_method"):
                        st.write(f"**è½¬å½•æ–¹æ³•:** {metadata['transcription_method']}")

                with tech_col2:
                    if metadata.get("view_count"):
                        st.write(f"**è§‚çœ‹æ¬¡æ•°:** {metadata['view_count']:,}")
                    if metadata.get("vehicle_confidence"):
                        confidence = metadata['vehicle_confidence']
                        st.write(f"**è½¦è¾†è¯†åˆ«ç½®ä¿¡åº¦:** {confidence:.1%}")

            # Content section
            st.markdown("**ğŸ“„ æ–‡æ¡£å†…å®¹:**")
            if content:
                if len(content) > 500:
                    st.text_area("å†…å®¹é¢„è§ˆ", content[:500] + "...", height=150, disabled=True, key=f"preview_content_{index}")
                    st.caption("ğŸ’¡ æŸ¥çœ‹è¯¦ç»†å…ƒæ•°æ®å¯ä»¥çœ‹åˆ°å®Œæ•´å†…å®¹åˆ†æ")
                else:
                    st.text_area("æ–‡æ¡£å†…å®¹", content, height=200, disabled=True, key=f"content_{index}")
            else:
                st.warning("æ­¤æ–‡æ¡£æ²¡æœ‰å†…å®¹")

        # Show detailed metadata analysis if expanded
        if st.session_state.get(metadata_key, False):
            st.markdown("---")
            st.markdown("**ğŸ” è¯¦ç»†å…ƒæ•°æ®åˆ†æ:**")
            # FIXED: Add unique_id to prevent key conflicts
            unique_id = f"doc_detailed_{index}"
            render_embedded_metadata_display(doc, show_full_content=True, unique_id=unique_id)

        st.divider()


def display_enhanced_statistics(documents: List[Dict]):
    """Display enhanced statistics with metadata analysis"""
    st.subheader(f"ğŸ“Š æ–‡æ¡£ç»Ÿè®¡ (å…± {len(documents)} ä¸ª)")

    # Calculate enhanced statistics
    source_counts = {}
    total_words = 0
    docs_with_embedded_metadata = 0
    docs_with_vehicle_info = 0
    unique_vehicles = set()
    metadata_injection_successes = 0
    total_metadata_fields = 0

    extractor = EmbeddedMetadataExtractor()

    for doc in documents:
        metadata = doc.get("metadata", {})
        content = doc.get("content", "")
        source = metadata.get("source", "unknown")

        source_counts[source] = source_counts.get(source, 0) + 1

        if content:
            total_words += len(content.split())

            # Check for embedded metadata
            embedded_metadata, _ = extractor.extract_embedded_metadata(content)
            if embedded_metadata:
                docs_with_embedded_metadata += 1
                total_metadata_fields += len(embedded_metadata)

        # Check metadata injection status
        if metadata.get('metadata_injected'):
            metadata_injection_successes += 1

        # Check for vehicle info
        if metadata.get('has_vehicle_info') or metadata.get('model'):
            docs_with_vehicle_info += 1
            if metadata.get('model'):
                manufacturer = metadata.get('manufacturer', '')
                vehicle_name = f"{manufacturer} {metadata['model']}".strip()
                unique_vehicles.add(vehicle_name)

    # Display basic stats
    stats_cols = st.columns(len(source_counts) + 2)

    for i, (source, count) in enumerate(source_counts.items()):
        with stats_cols[i]:
            st.metric(format_document_source({"source": source}), count)

    with stats_cols[-2]:
        st.metric("ğŸ“ æ€»è¯æ•°", f"{total_words:,}")

    with stats_cols[-1]:
        st.metric("ğŸš— æ£€æµ‹åˆ°è½¦å‹", len(unique_vehicles))

    # Enhanced metadata quality metrics
    st.markdown("#### ğŸ” å…ƒæ•°æ®è´¨é‡åˆ†æ")
    quality_cols = st.columns(4)

    with quality_cols[0]:
        embedded_rate = (docs_with_embedded_metadata / len(documents) * 100) if documents else 0
        st.metric("ğŸ·ï¸ åµŒå…¥å…ƒæ•°æ®ç‡", f"{embedded_rate:.0f}%")

    with quality_cols[1]:
        injection_rate = (metadata_injection_successes / len(documents) * 100) if documents else 0
        st.metric("ğŸ’‰ æ³¨å…¥æˆåŠŸç‡", f"{injection_rate:.0f}%")

    with quality_cols[2]:
        vehicle_rate = (docs_with_vehicle_info / len(documents) * 100) if documents else 0
        st.metric("ğŸš— è½¦è¾†æ£€æµ‹ç‡", f"{vehicle_rate:.0f}%")

    with quality_cols[3]:
        avg_fields = total_metadata_fields / max(docs_with_embedded_metadata, 1)
        st.metric("ğŸ“Š å¹³å‡å…ƒæ•°æ®å­—æ®µ", f"{avg_fields:.1f}")

    # Quality assessment
    if embedded_rate > 80:
        st.success("ğŸ¯ æ–‡æ¡£è´¨é‡ä¼˜ç§€ï¼šå¤§éƒ¨åˆ†æ–‡æ¡£åŒ…å«ä¸°å¯Œçš„å…ƒæ•°æ®")
    elif embedded_rate > 50:
        st.warning("âš¡ æ–‡æ¡£è´¨é‡è‰¯å¥½ï¼šéƒ¨åˆ†æ–‡æ¡£ç¼ºå°‘å…ƒæ•°æ®")
    else:
        st.error("ğŸ”§ æ–‡æ¡£è´¨é‡éœ€è¦æ”¹è¿›ï¼šå…ƒæ•°æ®è¦†ç›–ç‡è¾ƒä½")

    # Show detected vehicles if any
    if unique_vehicles:
        st.markdown("**ğŸš— æ£€æµ‹åˆ°çš„è½¦å‹:**")
        vehicles_list = list(unique_vehicles)[:10]  # Show first 10
        vehicles_display = ", ".join(vehicles_list)
        st.info(vehicles_display)
        if len(unique_vehicles) > 10:
            st.caption(f"... è¿˜æœ‰ {len(unique_vehicles) - 10} ä¸ªè½¦å‹")

    st.markdown("---")


# === FILTERS AND CONTROLS ===
st.subheader("ğŸ” ç­›é€‰é€‰é¡¹")

filter_col1, filter_col2, filter_col3, filter_col4 = st.columns(4)

with filter_col1:
    source_filter = st.selectbox(
        "æ–‡æ¡£æ¥æº",
        ["å…¨éƒ¨", "youtube", "bilibili", "pdf", "manual"],
        help="æŒ‰æ–‡æ¡£æ¥æºç±»å‹ç­›é€‰"
    )

with filter_col2:
    limit = st.selectbox(
        "æ˜¾ç¤ºæ•°é‡",
        [50, 100, 200, 500],
        index=1,
        help="é™åˆ¶æ˜¾ç¤ºçš„æ–‡æ¡£æ•°é‡"
    )

with filter_col3:
    sort_by = st.selectbox(
        "æ’åºæ–¹å¼",
        ["é»˜è®¤", "æŒ‰æ ‡é¢˜", "æŒ‰æ¥æº", "æŒ‰æ—¥æœŸ", "æŒ‰å…ƒæ•°æ®è´¨é‡"],
        help="æ–‡æ¡£æ’åºæ–¹å¼"
    )

with filter_col4:
    quality_filter = st.selectbox(
        "å…ƒæ•°æ®è´¨é‡",
        ["å…¨éƒ¨", "ä¼˜ç§€", "è‰¯å¥½", "ç¼ºå¤±"],
        help="æŒ‰å…ƒæ•°æ®è´¨é‡ç­›é€‰"
    )

# Control buttons
control_col1, control_col2 = st.columns(2)

with control_col1:
    if st.button("ğŸ”„ åˆ·æ–°æ–‡æ¡£åˆ—è¡¨", use_container_width=True):
        st.rerun()

with control_col2:
    if st.button("ğŸ“Š æ˜¾ç¤ºè¯¦ç»†ç»Ÿè®¡", use_container_width=True):
        st.session_state['show_detailed_stats'] = not st.session_state.get('show_detailed_stats', False)
        st.rerun()

# === DOCUMENT LOADING AND PROCESSING ===
with st.spinner("æ­£åœ¨åŠ è½½æ–‡æ¡£..."):
    documents = get_vector_store_documents(
        limit=limit,
        source_filter=source_filter if source_filter != "å…¨éƒ¨" else None
    )

if documents:
    # Apply quality filtering
    if quality_filter != "å…¨éƒ¨":
        extractor = EmbeddedMetadataExtractor()
        filtered_docs = []

        for doc in documents:
            content = doc.get("content", "")
            metadata = doc.get("metadata", {})
            embedded_metadata, _ = extractor.extract_embedded_metadata(content)

            if quality_filter == "ä¼˜ç§€":
                if metadata.get('metadata_injected') and len(embedded_metadata) > 2:
                    filtered_docs.append(doc)
            elif quality_filter == "è‰¯å¥½":
                if len(embedded_metadata) > 0:
                    filtered_docs.append(doc)
            elif quality_filter == "ç¼ºå¤±":
                if len(embedded_metadata) == 0:
                    filtered_docs.append(doc)

        documents = filtered_docs

    # Display enhanced statistics
    display_enhanced_statistics(documents)

    # Show detailed statistics if requested
    if st.session_state.get('show_detailed_stats', False):
        st.subheader("ğŸ“ˆ è¯¦ç»†ç»Ÿè®¡åˆ†æ")

        with st.expander("æŸ¥çœ‹å¤„ç†è´¨é‡åˆ†å¸ƒ", expanded=True):
            # Create processing quality distribution
            quality_distribution = {"ä¼˜ç§€": 0, "è‰¯å¥½": 0, "ä¸€èˆ¬": 0, "ç¼ºå¤±": 0}
            extractor = EmbeddedMetadataExtractor()

            for doc in documents:
                content = doc.get("content", "")
                metadata = doc.get("metadata", {})
                embedded_metadata, _ = extractor.extract_embedded_metadata(content)

                if metadata.get('metadata_injected') and len(embedded_metadata) > 2:
                    quality_distribution["ä¼˜ç§€"] += 1
                elif len(embedded_metadata) > 1:
                    quality_distribution["è‰¯å¥½"] += 1
                elif len(embedded_metadata) > 0:
                    quality_distribution["ä¸€èˆ¬"] += 1
                else:
                    quality_distribution["ç¼ºå¤±"] += 1

            # Display distribution
            dist_cols = st.columns(4)
            for i, (quality, count) in enumerate(quality_distribution.items()):
                with dist_cols[i]:
                    percentage = (count / len(documents) * 100) if documents else 0
                    st.metric(f"{quality}è´¨é‡", f"{count} ({percentage:.1f}%)")

    # Sort documents
    if sort_by == "æŒ‰æ ‡é¢˜":
        documents.sort(key=lambda x: x.get("metadata", {}).get("title", ""))
    elif sort_by == "æŒ‰æ¥æº":
        documents.sort(key=lambda x: x.get("metadata", {}).get("source", ""))
    elif sort_by == "æŒ‰æ—¥æœŸ":
        documents.sort(key=lambda x: x.get("metadata", {}).get("published_date", ""), reverse=True)
    elif sort_by == "æŒ‰å…ƒæ•°æ®è´¨é‡":
        # Sort by metadata quality (embedded metadata count)
        extractor = EmbeddedMetadataExtractor()
        def get_metadata_score(doc):
            content = doc.get("content", "")
            metadata = doc.get("metadata", {})
            embedded_metadata, _ = extractor.extract_embedded_metadata(content)
            injection_bonus = 1 if metadata.get('metadata_injected') else 0
            return len(embedded_metadata) + injection_bonus

        documents.sort(key=get_metadata_score, reverse=True)

    # Display documents
    st.subheader("ğŸ“š æ–‡æ¡£åˆ—è¡¨")

    for i, doc in enumerate(documents):
        display_enhanced_document_card(doc, i)

else:
    st.info("ğŸ“­ æœªæ‰¾åˆ°æ–‡æ¡£")
    st.markdown("""
    **å¯èƒ½çš„åŸå› :**
    - å‘é‡æ•°æ®åº“ä¸­æš‚æ— æ–‡æ¡£
    - ç­›é€‰æ¡ä»¶è¿‡äºä¸¥æ ¼
    - æœåŠ¡æš‚æ—¶ä¸å¯ç”¨

    **å»ºè®®æ“ä½œ:**
    - å°è¯•ä¸Šä¼ ä¸€äº›æ–‡æ¡£
    - è°ƒæ•´ç­›é€‰æ¡ä»¶
    - æ£€æŸ¥ç³»ç»ŸçŠ¶æ€
    """)

# === NAVIGATION ===
st.markdown("---")
nav_cols = st.columns(4)

with nav_cols[0]:
    if st.button("ğŸ“¤ ä¸Šä¼ æ–‡æ¡£", use_container_width=True):
        st.switch_page("pages/æ•°æ®æ‘„å–.py")

with nav_cols[1]:
    if st.button("ğŸ§  æ™ºèƒ½æŸ¥è¯¢", use_container_width=True):
        st.switch_page("pages/æ™ºèƒ½æŸ¥è¯¢.py")

with nav_cols[2]:
    if st.button("ğŸ“‹ æŸ¥çœ‹ä»»åŠ¡", use_container_width=True):
        st.switch_page("pages/åå°ä»»åŠ¡.py")

with nav_cols[3]:
    if st.button("ğŸ  è¿”å›ä¸»é¡µ", use_container_width=True):
        st.switch_page("src/ui/ä¸»é¡µ.py")

st.caption("ğŸ” æ–‡æ¡£æµè§ˆ - æŸ¥çœ‹å‘é‡æ•°æ®åº“ä¸­çš„æ‰€æœ‰æ–‡æ¡£ï¼ŒåŒ…å«è¯¦ç»†å…ƒæ•°æ®åˆ†æ")