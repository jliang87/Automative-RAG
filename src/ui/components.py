"""
Streamlit ç•Œé¢ UI ç»„ä»¶

è¯¥æ¨¡å—åŒ…å« Streamlit åº”ç”¨ç¨‹åºä¸­çš„å¯å¤ç”¨ UI ç»„ä»¶ã€‚
"""

import streamlit as st
import httpx
from typing import Dict, List, Optional, Union, Callable, Any


def header(title: str, description: Optional[str] = None):
    """æ˜¾ç¤ºé¡µé¢æ ‡é¢˜å’Œæè¿°"""
    st.title(title)
    if description:
        st.markdown(description)
    st.divider()


def api_status_indicator():
    """æ˜¾ç¤º API è¿æ¥çŠ¶æ€"""
    try:
        with httpx.Client() as client:
            response = client.get(
                f"{st.session_state.api_url}/health",
                headers={"x-token": st.session_state.api_key},
                timeout=3.0
            )

        if response.status_code == 200:
            st.sidebar.success("âœ… API è¿æ¥æ­£å¸¸")
            return True
        else:
            st.sidebar.error(f"âŒ API é”™è¯¯: {response.status_code}")
            return False
    except Exception as e:
        st.sidebar.error(f"âŒ è¿æ¥å¤±è´¥: {str(e)}")
        return False


def gpu_status_indicator():
    """æ˜¾ç¤º GPU çŠ¶æ€ä¿¡æ¯"""
    try:
        with httpx.Client() as client:
            response = client.get(
                f"{st.session_state.api_url}/ingest/status",
                headers={"x-token": st.session_state.api_key},
                timeout=3.0
            )

        if response.status_code == 200:
            data = response.json()

            if "gpu_info" in data and data["gpu_info"]:
                gpu_info = data["gpu_info"]

                # åˆ›å»º GPU ä¿¡æ¯å±•å¼€åŒºåŸŸ
                with st.sidebar.expander("GPU çŠ¶æ€"):
                    if "device_name" in gpu_info:
                        st.info(f"GPU: {gpu_info['device_name']}")

                    if "memory_allocated" in gpu_info:
                        st.metric("æ˜¾å­˜å ç”¨", gpu_info['memory_allocated'])

                    if "whisper_model" in gpu_info:
                        st.text(f"Whisper ç‰ˆæœ¬: {gpu_info['whisper_model']}")

                    if "fp16_enabled" in gpu_info:
                        fp16 = gpu_info['fp16_enabled']
                        st.text(f"æ··åˆç²¾åº¦: {'âœ“' if fp16 else 'âœ—'}")
            else:
                st.sidebar.warning("âš ï¸ å½“å‰è¿è¡Œåœ¨ CPU ä¸Š")

    except Exception as e:
        st.sidebar.warning("âš ï¸ æ— æ³•è·å– GPU çŠ¶æ€")


def llm_status_indicator():
    """æ˜¾ç¤º LLMï¼ˆå¤§è¯­è¨€æ¨¡å‹ï¼‰çŠ¶æ€ä¿¡æ¯"""
    try:
        with httpx.Client() as client:
            response = client.get(
                f"{st.session_state.api_url}/query/llm-info",
                headers={"x-token": st.session_state.api_key},
                timeout=3.0
            )

        if response.status_code == 200:
            llm_info = response.json()

            with st.sidebar.expander("LLM çŠ¶æ€"):
                # æ¨¡å‹åç§° - è‹¥åç§°è¿‡é•¿ï¼Œåˆ™æ˜¾ç¤ºç¼©çŸ­ç‰ˆæœ¬
                model_name = llm_info.get("model_name", "æœªçŸ¥")
                if len(model_name) > 30:
                    display_name = f"{model_name.split('/')[-1]}"
                else:
                    display_name = model_name
                st.info(f"æ¨¡å‹: {display_name}")

                # é‡åŒ–ä¿¡æ¯
                quant = llm_info.get("quantization", "æ— ")
                st.text(f"é‡åŒ–æ–¹å¼: {quant}")

                # æ˜¾å­˜å ç”¨ä¿¡æ¯
                if "vram_usage" in llm_info:
                    st.metric("æ˜¾å­˜å ç”¨", llm_info["vram_usage"])

                # è®¾å¤‡ä¿¡æ¯
                device = llm_info.get("device", "æœªçŸ¥")
                st.text(f"è¿è¡Œè®¾å¤‡: {device}")
    except Exception:
        pass  # å¿½ç•¥é”™è¯¯


def metadata_filters():
    """æ¸²æŸ“å…ƒæ•°æ®ç­›é€‰é€‰é¡¹"""
    st.subheader("ç­›é€‰æ¡ä»¶")

    col1, col2 = st.columns(2)

    with col1:
        # è¿™äº›é€‰é¡¹åº”è¯¥ä» API è·å–
        manufacturers = ["", "ä¸°ç”°", "æœ¬ç”°", "ç¦ç‰¹", "å®é©¬", "ç‰¹æ–¯æ‹‰"]
        manufacturer = st.selectbox("å‚å•†", manufacturers)

        years = [""] + [str(year) for year in range(2010, 2026)]
        year = st.selectbox("å¹´ä»½", years)

        categories = ["", "è½¿è½¦", "SUV", "å¡è½¦", "è·‘è½¦", "MPV"]
        category = st.selectbox("è½¦å‹", categories)

    with col2:
        models = [""]
        if manufacturer == "ä¸°ç”°":
            models += ["å‡¯ç¾ç‘", "å¡ç½—æ‹‰", "RAV4", "æ±‰å…°è¾¾"]
        elif manufacturer == "æœ¬ç”°":
            models += ["æ€åŸŸ", "é›…é˜", "CR-V", "Pilot"]
        elif manufacturer == "ç¦ç‰¹":
            models += ["é‡é©¬", "F-150", "æ¢é™©è€…", "Escape"]
        elif manufacturer == "å®é©¬":
            models += ["3ç³»", "5ç³»", "X3", "X5"]
        elif manufacturer == "ç‰¹æ–¯æ‹‰":
            models += ["Model S", "Model 3", "Model X", "Model Y"]

        model = st.selectbox("è½¦å‹", models)

        engine_types = ["", "æ±½æ²¹", "æŸ´æ²¹", "ç”µåŠ¨", "æ··åˆåŠ¨åŠ›"]
        engine_type = st.selectbox("å‘åŠ¨æœºç±»å‹", engine_types)

        transmission_types = ["", "è‡ªåŠ¨", "æ‰‹åŠ¨", "CVT", "DCT"]
        transmission = st.selectbox("å˜é€Ÿç®±", transmission_types)

    # æ„å»ºç­›é€‰æ¡ä»¶
    metadata_filter = {}

    if manufacturer:
        metadata_filter["manufacturer"] = manufacturer
    if model:
        metadata_filter["model"] = model
    if year:
        metadata_filter["year"] = int(year)
    if category:
        metadata_filter["category"] = category
    if engine_type:
        metadata_filter["engine_type"] = engine_type
    if transmission:
        metadata_filter["transmission"] = transmission

    return metadata_filter if metadata_filter else None


def api_request(
    endpoint: str,
    method: str = "GET",
    data: Optional[Dict] = None,
    files: Optional[Dict] = None,
    params: Optional[Dict] = None,
    handle_error: Callable[[str], Any] = None,
) -> Optional[Dict]:
    """å‘é€ API è¯·æ±‚å¹¶å¤„ç†é”™è¯¯"""
    headers = {"x-token": st.session_state.api_key}
    url = f"{st.session_state.api_url}{endpoint}"

    try:
        with httpx.Client(timeout=150.0) as client:
            if method == "GET":
                response = client.get(url, headers=headers, params=params)
            elif method == "POST":
                if files:
                    response = client.post(url, headers=headers, data=data, files=files)
                else:
                    response = client.post(url, headers=headers, json=data)
            elif method == "DELETE":
                response = client.delete(url, headers=headers)
            else:
                st.error(f"ä¸æ”¯æŒçš„è¯·æ±‚æ–¹æ³•: {method}")
                return None

            if response.status_code >= 400:
                error_msg = f"API é”™è¯¯ ({response.status_code}): {response.text}"
                if handle_error:
                    return handle_error(error_msg)
                else:
                    st.error(error_msg)
                    return None

            return response.json()
    except Exception as e:
        error_msg = f"è¿æ¥é”™è¯¯: {str(e)}"
        if handle_error:
            return handle_error(error_msg)
        else:
            st.error(error_msg)
            return None


def display_document(doc: Dict, index: int):
    """å±•ç¤ºæœç´¢ç»“æœæ–‡æ¡£"""
    metadata = doc.get("metadata", {})

    # ç¡®å®šæ¥æºå›¾æ ‡
    source_type = metadata.get("source", "æœªçŸ¥")
    source_icon = "ğŸ“š"
    if source_type == "youtube":
        source_icon = "ğŸ¬"
    elif source_type == "pdf":
        source_icon = "ğŸ“„"
    elif source_type == "manual":
        source_icon = "ğŸ“"

    title = metadata.get("title", f"æ–‡æ¡£ {index+1}")

    with st.expander(f"{source_icon} {title}"):
        st.caption(f"æ¥æº: {source_type}")
        st.caption(f"ç›¸å…³åº¦: {doc.get('relevance_score', 0):.4f}")

        auto_info = [metadata.get("manufacturer", ""), metadata.get("model", ""), str(metadata.get("year", ""))]
        st.markdown(f"**è½¦å‹**: {' '.join([x for x in auto_info if x])}")

        st.markdown("---")
        st.markdown(doc.get("content", ""))

        if metadata.get("url"):
            st.markdown(f"[åŸå§‹é“¾æ¥]({metadata['url']})")


def loading_spinner(text: str = "å¤„ç†ä¸­..."):
    """åˆ›å»ºåŠ è½½åŠ¨ç”»"""
    return st.spinner(text)
