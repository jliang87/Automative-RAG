"""
Enhanced job chain visualization component for the new self-triggering architecture.
This should be added as src/ui/job_chain_visualization.py
"""

import streamlit as st
import time
import json
from typing import Dict, List, Any, Optional
import pandas as pd

from src.ui.api_client import api_request


def display_job_chain_progress(job_id: str, job_data: Dict[str, Any]) -> Dict[str, Any]:
    """
    Display detailed job chain progress with self-triggering workflow visualization.

    Args:
        job_id: Job identifier
        job_data: Job data from the tracker

    Returns:
        Dictionary with user actions (retry, cancel, etc.)
    """
    # Get job chain status
    chain_status = api_request(
        endpoint=f"/job-chains/{job_id}",
        method="GET"
    )

    if not chain_status:
        st.warning("æ— æ³•è·å–ä½œä¸šé“¾çŠ¶æ€")
        return {"action": None}

    # Extract job chain information
    job_chain_data = chain_status.get("job_chain", {})
    combined_view = chain_status.get("combined_view", {})

    # Display job chain header
    st.subheader(f"è‡ªè§¦å‘ä½œä¸šé“¾: {job_id}")

    # Job chain overview
    col1, col2, col3, col4 = st.columns(4)

    with col1:
        st.metric("ä½œä¸šçŠ¶æ€", combined_view.get("status", "unknown"))

    with col2:
        progress = combined_view.get("progress", 0)
        st.metric("å®Œæˆè¿›åº¦", f"{progress:.1f}%")

    with col3:
        current_task = combined_view.get("current_task", "æ— ")
        st.metric("å½“å‰ä»»åŠ¡", current_task)

    with col4:
        total_steps = combined_view.get("total_steps", 0)
        current_step = job_chain_data.get("current_step", 0)
        st.metric("æ­¥éª¤è¿›åº¦", f"{current_step}/{total_steps}")

    # Workflow visualization
    workflow = job_chain_data.get("workflow", [])
    if workflow:
        st.subheader("ä½œä¸šé“¾å·¥ä½œæµ")

        # Create workflow steps visualization
        workflow_data = []
        step_timings = combined_view.get("step_timings", {})
        current_step_idx = job_chain_data.get("current_step", 0)

        for i, (task_name, queue_name) in enumerate(workflow):
            # Determine step status
            if i < current_step_idx:
                status = "âœ… å·²å®Œæˆ"
                color = "green"
            elif i == current_step_idx:
                status = "ğŸ”„ è¿›è¡Œä¸­"
                color = "blue"
            else:
                status = "â³ å¾…å¤„ç†"
                color = "gray"

            # Get timing information
            timing_info = step_timings.get(task_name, {})
            duration = timing_info.get("duration", 0)

            if duration > 0:
                if duration < 60:
                    duration_str = f"{duration:.1f}ç§’"
                else:
                    duration_str = f"{duration / 60:.1f}åˆ†é’Ÿ"
            else:
                duration_str = "-"

            # Map queue to worker type
            worker_mapping = {
                "cpu_tasks": "CPUå¤„ç†å™¨",
                "transcription_tasks": "GPU-Whisper",
                "embedding_tasks": "GPU-åµŒå…¥",
                "inference_tasks": "GPU-æ¨ç†"
            }

            worker_type = worker_mapping.get(queue_name, queue_name)

            workflow_data.append({
                "æ­¥éª¤": f"{i + 1}. {task_name}",
                "Workerç±»å‹": worker_type,
                "é˜Ÿåˆ—": queue_name,
                "çŠ¶æ€": status,
                "ç”¨æ—¶": duration_str
            })

        # Display workflow table
        workflow_df = pd.DataFrame(workflow_data)
        st.dataframe(workflow_df, hide_index=True, use_container_width=True)

        # Progress bar for overall completion
        if total_steps > 0:
            progress_value = min(current_step_idx / total_steps, 1.0)
            st.progress(progress_value, text=f"ä½œä¸šé“¾è¿›åº¦: {progress_value * 100:.1f}%")

    # Self-triggering information
    with st.expander("è‡ªè§¦å‘æœºåˆ¶è¯¦æƒ…", expanded=False):
        st.markdown("""
        **è‡ªè§¦å‘ä½œä¸šé“¾ç‰¹ç‚¹:**
        - æ— éœ€è½®è¯¢ï¼Œä»»åŠ¡å®Œæˆè‡ªåŠ¨è§¦å‘ä¸‹ä¸€æ­¥
        - äº‹ä»¶é©±åŠ¨æ¶æ„ï¼Œé™ä½ç³»ç»Ÿå¼€é”€
        - æ¯ä¸ªä»»åŠ¡å®Œæˆåç«‹å³ä¼ é€’åˆ°ä¸‹ä¸€ä¸ªWorker
        - æ”¯æŒä»»åŠ¡å¤±è´¥æ—¶çš„è‡ªåŠ¨é‡è¯•å’Œæ¢å¤

        **Workerä¸“ç”¨åŒ–:**
        - æ¯ç§ä»»åŠ¡ç±»å‹åˆ†é…åˆ°ä¸“ç”¨GPU Worker
        - æ¶ˆé™¤æ¨¡å‹åŠ è½½/å¸è½½å¼€é”€
        - æ”¯æŒçœŸæ­£çš„å¹¶è¡Œå¤„ç†
        """)

        # Show detailed step timings if available
        if step_timings:
            st.subheader("è¯¦ç»†è®¡æ—¶ä¿¡æ¯")
            timing_data = []

            for task_name, timing in step_timings.items():
                started_at = timing.get("started_at")
                completed_at = timing.get("completed_at")
                duration = timing.get("duration", 0)

                if started_at:
                    start_time = time.strftime("%H:%M:%S", time.localtime(started_at))
                else:
                    start_time = "-"

                if completed_at:
                    end_time = time.strftime("%H:%M:%S", time.localtime(completed_at))
                else:
                    end_time = "-"

                timing_data.append({
                    "ä»»åŠ¡": task_name,
                    "å¼€å§‹æ—¶é—´": start_time,
                    "ç»“æŸæ—¶é—´": end_time,
                    "æŒç»­æ—¶é—´": f"{duration:.2f}ç§’" if duration > 0 else "-"
                })

            if timing_data:
                timing_df = pd.DataFrame(timing_data)
                st.dataframe(timing_df, hide_index=True, use_container_width=True)

    # Action buttons based on job status
    status = combined_view.get("status", "")

    if status == "failed":
        st.error("ä½œä¸šé“¾æ‰§è¡Œå¤±è´¥")
        if st.button("é‡è¯•ä½œä¸šé“¾", key=f"retry_chain_{job_id}"):
            return {"action": "retry", "job_id": job_id}

    elif status == "processing":
        if st.button("å–æ¶ˆä½œä¸šé“¾", key=f"cancel_chain_{job_id}"):
            return {"action": "cancel", "job_id": job_id}

    elif status == "completed":
        st.success("âœ… ä½œä¸šé“¾æ‰§è¡Œå®Œæˆ")

        # Show final results
        final_result = job_data.get("result", {})
        if isinstance(final_result, dict):
            with st.expander("æœ€ç»ˆç»“æœ", expanded=True):
                # Format results based on job type
                job_type = job_data.get("job_type", "")

                if "document_count" in final_result:
                    st.metric("ç”Ÿæˆæ–‡æ¡£æ•°", final_result["document_count"])

                if "embedding_completed_at" in final_result:
                    st.success("âœ… å‘é‡åµŒå…¥å·²å®Œæˆ")

                if "total_duration" in final_result:
                    duration = final_result["total_duration"]
                    if duration < 60:
                        duration_str = f"{duration:.1f}ç§’"
                    else:
                        duration_str = f"{duration / 60:.1f}åˆ†é’Ÿ"
                    st.metric("æ€»å¤„ç†æ—¶é—´", duration_str)

    return {"action": None}


def display_queue_worker_mapping():
    """
    Display the mapping between queues and dedicated workers.
    """
    st.subheader("é˜Ÿåˆ—åˆ°Workeræ˜ å°„")

    mapping_data = [
        {
            "é˜Ÿåˆ—åç§°": "transcription_tasks",
            "ä¸“ç”¨Worker": "gpu-whisper",
            "æ¨¡å‹": "Whisper Medium",
            "GPUåˆ†é…": "2GB",
            "å¤„ç†ç±»å‹": "è§†é¢‘éŸ³é¢‘è½¬å½•"
        },
        {
            "é˜Ÿåˆ—åç§°": "embedding_tasks",
            "ä¸“ç”¨Worker": "gpu-embedding",
            "æ¨¡å‹": "BGE-M3",
            "GPUåˆ†é…": "3GB",
            "å¤„ç†ç±»å‹": "æ–‡æ¡£å‘é‡åµŒå…¥"
        },
        {
            "é˜Ÿåˆ—åç§°": "inference_tasks",
            "ä¸“ç”¨Worker": "gpu-inference",
            "æ¨¡å‹": "DeepSeek-R1 + ColBERT",
            "GPUåˆ†é…": "6GB",
            "å¤„ç†ç±»å‹": "LLMæ¨ç†å’Œé‡æ’åº"
        },
        {
            "é˜Ÿåˆ—åç§°": "cpu_tasks",
            "ä¸“ç”¨Worker": "cpu",
            "æ¨¡å‹": "N/A",
            "GPUåˆ†é…": "0GB",
            "å¤„ç†ç±»å‹": "PDFè§£æå’Œæ–‡æœ¬å¤„ç†"
        }
    ]

    mapping_df = pd.DataFrame(mapping_data)
    st.dataframe(mapping_df, hide_index=True, use_container_width=True)

    # Current queue status
    queue_status = api_request(
        endpoint="/query/queue-status",
        method="GET"
    )

    if queue_status:
        st.subheader("å®æ—¶é˜Ÿåˆ—çŠ¶æ€")

        current_status = []
        for queue_data in mapping_data:
            queue_name = queue_data["é˜Ÿåˆ—åç§°"]
            queue_info = queue_status.get("queue_status", {}).get(queue_name, {})

            status = queue_info.get("status", "free")
            waiting_tasks = queue_info.get("waiting_tasks", 0)

            if status == "busy":
                current_job = queue_info.get("current_job", "unknown")
                status_display = f"ğŸ”„ å¿™ç¢Œ (ä½œä¸š: {current_job[:8]}...)"
            elif waiting_tasks > 0:
                status_display = f"â³ {waiting_tasks}ä¸ªä»»åŠ¡ç­‰å¾…"
            else:
                status_display = "âœ… ç©ºé—²"

            current_status.append({
                "é˜Ÿåˆ—": queue_name,
                "Workerç±»å‹": queue_data["ä¸“ç”¨Worker"],
                "å½“å‰çŠ¶æ€": status_display
            })

        status_df = pd.DataFrame(current_status)
        st.dataframe(status_df, hide_index=True, use_container_width=True)


def display_job_chain_overview():
    """
    Display system-wide job chain overview.
    """
    # Get job chains overview
    overview = api_request(
        endpoint="/job-chains",
        method="GET"
    )

    if not overview:
        st.warning("æ— æ³•è·å–ä½œä¸šé“¾æ¦‚è§ˆ")
        return

    st.subheader("ç³»ç»Ÿä½œä¸šé“¾æ¦‚è§ˆ")

    # Overall statistics
    col1, col2, col3 = st.columns(3)

    with col1:
        active_chains = overview.get("active_chains", [])
        st.metric("æ´»è·ƒä½œä¸šé“¾", len(active_chains))

    with col2:
        queue_status = overview.get("queue_status", {})
        busy_queues = sum(1 for q in queue_status.values() if q.get("status") == "busy")
        st.metric("å¿™ç¢Œé˜Ÿåˆ—", busy_queues)

    with col3:
        total_waiting = sum(q.get("waiting_tasks", 0) for q in queue_status.values())
        st.metric("ç­‰å¾…ä»»åŠ¡æ€»æ•°", total_waiting)

    # Active job chains
    if active_chains:
        st.subheader("æ´»è·ƒä½œä¸šé“¾")

        chain_data = []
        for chain in active_chains:
            job_id = chain.get("job_id", "unknown")
            job_type = chain.get("job_type", "unknown")
            current_task = chain.get("current_task", "æ— ")
            progress = chain.get("progress_percentage", 0)

            chain_data.append({
                "ä½œä¸šID": job_id[:8] + "...",
                "ç±»å‹": job_type,
                "å½“å‰ä»»åŠ¡": current_task,
                "è¿›åº¦": f"{progress:.1f}%"
            })

        chain_df = pd.DataFrame(chain_data)
        st.dataframe(chain_df, hide_index=True, use_container_width=True)
    else:
        st.info("å½“å‰æ²¡æœ‰æ´»è·ƒçš„ä½œä¸šé“¾")

    # System performance metrics
    with st.expander("ç³»ç»Ÿæ€§èƒ½æŒ‡æ ‡", expanded=False):
        st.markdown("""
        **è‡ªè§¦å‘æ¶æ„ä¼˜åŠ¿:**
        - é›¶è½®è¯¢å¼€é”€ï¼Œäº‹ä»¶é©±åŠ¨æ‰§è¡Œ
        - æ¯«ç§’çº§ä»»åŠ¡åˆ‡æ¢å»¶è¿Ÿ
        - ä¸“ç”¨Workeræ— æ¨¡å‹é¢ ç°¸
        - æ”¯æŒçœŸæ­£çš„ä»»åŠ¡å¹¶è¡Œæ€§

        **å†…å­˜ä¼˜åŒ–:**
        - Whisper Worker: å›ºå®š2GBåˆ†é…
        - åµŒå…¥Worker: å›ºå®š3GBåˆ†é…  
        - æ¨ç†Worker: å›ºå®š6GBåˆ†é…
        - é¿å…åŠ¨æ€å†…å­˜åˆ†é…å¯¼è‡´çš„ç¢ç‰‡åŒ–
        """)